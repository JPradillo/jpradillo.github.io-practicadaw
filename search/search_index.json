{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Tema 2","text":""},{"location":"#introduccion","title":"Introducci\u00f3n","text":"<p>Con la evoluci\u00f3n y el acceso libre a Internet, uno de los principales alicientes que han surgido es la publicaci\u00f3n de p\u00e1ginas web donde se pueden almacenar unos contenidos bastante atractivos para nosotros y que, al mismo tiempo, pueden ser consultados desde cualquier del mundo para todos.</p> <p>Cabe decir que, con la popularizaci\u00f3n de Internet, tanto empresas como usuarios han visto la necesidad de establecer un punto desde donde anunciar sus productos, o bien, a t\u00edtulo particular, dar publicidad a las aficiones o capacidades personales mediante la publicaci\u00f3n de p\u00e1ginas web.</p> <p>Las p\u00e1ginas web, en su mayor\u00eda en formato HTML, requieren ser alojadas en m\u00e1quinas que dispongan de espacio en disco para almacenar archivos HTML, im\u00e1genes, bloques de c\u00f3digo o archivos de v\u00eddeo en directorios espec\u00edficos y, al mismo tiempo, deben ser capaces de entender todo tipo de extensi\u00f3n de los archivos que son enviados en ambos sentidos de la comunicaci\u00f3n.</p> <p>Paralelamente, no podemos dejar de lado la importancia de las medidas de seguridad ante los peligros existentes en Internet. Para ello, las p\u00e1ginas deber\u00e1n estar dise\u00f1adas considerando la incorporaci\u00f3n de protocolos de comunicaci\u00f3n seguros como, por ejemplo, los desarrollados con el protocolo seguro de transferencia de hipertexto (HTTPS, Hyper Text Transfer Protocol secure) que utilizan claves y estrategias de cifrado propias de las herramientas del protocolo de capa de conexi\u00f3n segura (SSL, secure sockets layer).</p> <p>Las m\u00e1quinas que alojan las p\u00e1ginas web reciben la categor\u00eda de servidores web. Desde el punto de vista de los servidores, los requerimientos m\u00e1s relevantes son el espacio de disco necesario para poder almacenar la estructura de la p\u00e1gina web y una buena conexi\u00f3n de red para que el consumo de la unidad de procesamiento central (CPU, central processing unit ) sea bastante bajo.</p> <p>El funcionamiento de los servidores web es especial ya que, como si se tratara de un diente de sierra, tienen consumos de recursos puntuales porque podemos estar un tiempo sin peticiones y, de repente, tener una avalancha de peticiones. Esto hace que los servidores web suelan tener un n\u00famero bajo de procesos en espera. A medida que resultan necesarios, se van arrancando nuevos.</p> <p>Cabe decir que no todas las peticiones consumen el mismo, y, por ejemplo, aquellas p\u00e1ginas web que ejecuten programas de interacci\u00f3n con el usuario o requieran cifrado (HTTPS) consumen m\u00e1s recursos que otras p\u00e1ginas web con menos interacci\u00f3n.</p>"},{"location":"#que-es-un-servidor-web","title":"\u00bfQu\u00e9 es un servidor web?","text":"<p>Los servidores web sirven para almacenar contenidos de Internet y facilitar su disponibilidad de forma constante y segura. Cuando visitas una p\u00e1gina web desde tu navegador, es en realidad un servidor web el que env\u00eda los componentes individuales de dicha p\u00e1gina directamente a tu ordenador. Esto quiere decir que para que una p\u00e1gina web sea accesible en cualquier momento, el servidor web debe estar permanentemente online.</p> <p>Toda p\u00e1gina accesible en Internet necesita un servidor especial para sus contenidos web. A menudo, las grandes empresas y organizaciones cuentan con un servidor web propio para disponer sus contenidos en Intranet e Internet. Sin embargo, la mayor\u00eda de administradores recurren a los centros de datos de proveedores de alojamiento web para sus proyectos. Independientemente de si tienes un servidor web propio o de si alquilas uno externo, siempre necesitar\u00e1s un software para gestionar los datos de tu p\u00e1gina y mantenerla actualizada. En este sentido, tienes la posibilidad de elegir entre varias soluciones de software para servidores web dise\u00f1adas para diferentes aplicaciones y sistemas operativos.</p>"},{"location":"#tecnologia-de-servidores-web","title":"Tecnolog\u00eda de servidores web","text":"<p>Principalmente, el software de un servidor HTTP es el encargado de proporcionar los datos para la visualizaci\u00f3n del contenido web.</p> <p>Para abrir una p\u00e1gina web, el usuario solo tiene que escribir el URL correspondiente en la barra de direcciones de su navegador web. El navegador env\u00eda una solicitud al servidor web, quien responde, por ejemplo, entregando una p\u00e1gina HTML. Esta puede estar alojada como un documento est\u00e1tico en el host o ser generada de forma din\u00e1mica, lo que significa que el servidor web tiene que ejecutar un c\u00f3digo de programa (p. ej., Java o PHP) antes de tramitar su respuesta.</p> <p>El navegador interpreta la respuesta, lo que suele generar autom\u00e1ticamente m\u00e1s solicitudes al servidor a prop\u00f3sito de, por ejemplo, im\u00e1genes integradas o archivos CSS (hojas de estilos).</p> <p>El protocolo utilizado para la transmisi\u00f3n es HTTP (o su variante cifrada HTTPS), que se basa, a su vez, en los protocolos de red IP y TCP (y muy rara vez en UDP). Un servidor web puede entregar los contenidos simult\u00e1neamente a varios ordenadores o navegadores web. La cantidad de solicitudes (requests) y la velocidad con la que pueden ser procesadas depende, entre otras cosas, del hardware y la carga (n\u00famero de solicitudes) del host. Sin embargo, la complejidad del contenido tambi\u00e9n juega un papel importante: los contenidos web din\u00e1micos necesitan m\u00e1s recursos que los contenidos est\u00e1ticos.</p> <p>La selecci\u00f3n del equipo adecuado para el servidor y la decisi\u00f3n de si este debe ser dedicado, virtual o en la nube, se debe hacer pensando siempre en evitar sobrecargas en el servidor. Aunque se haya encontrado un servidor web que se adapta perfectamente a las necesidades del proyecto, siempre se corre el riesgo de que se presenten fallos en \u00e9l como consecuencia de imprecisiones t\u00e9cnicas o cortes de energ\u00eda en el centro de datos del host. Aunque no es muy frecuente, durante un per\u00edodo de inactividad de este tipo (downtime), la web no estar\u00e1 disponible.</p>"},{"location":"#otras-funciones-de-los-servidores-web","title":"Otras funciones de los servidores web","text":"<p>Aunque su principal funci\u00f3n es la transferencia de contenido web, muchos programas de servidor web ofrecen caracter\u00edsticas adicionales:</p> <p>Adem\u00e1s del software del servidor, un host puede contener otro tipo de programas, como por ejemplo un servidor FTP para la carga de archivos o un servidor de base de datos para contenidos din\u00e1micos. En general, existen diferentes tipos de servidores web que pueden ser utilizados para numerosos prop\u00f3sitos, por ejemplo, los servidores de correo, los servidores de juegos o los servidores proxy.</p>"},{"location":"#el-protocolo-http","title":"El protocolo HTTP","text":""},{"location":"#historia","title":"Historia","text":"<p>El protocolo de transferencia de hipertexto (HTTP, Hypertext Transfer Protocol) es el motor que da vida a Internet, ya que es la base para la web (www, world wide web).</p> <p>Desde un punto de vista hist\u00f3rico, la web fue creada en 1989 en el Consejo Europeo para la Investigaci\u00f3n Nuclear (CERN, Centro Europeene pour la Recherche Nucl\u00e9aire), con sede en Ginebra, justo en la frontera entre Suiza y Francia. Cabe decir que este organismo dispon\u00eda (y dispone) de una amplia plantilla de cient\u00edficos de diferentes pa\u00edses de Europa que trabajan en sus aceleradores de part\u00edculas. En consecuencia, muchos equipos de trabajadores est\u00e1n integrados por miembros de nacionalidades diferentes. Adem\u00e1s, muchos de los experimentos que se realizan destacan por su complejidad y requieren a\u00f1os y a\u00f1os de planificaci\u00f3n y de construcci\u00f3n de equipamientos.</p> <p>Fue a ra\u00edz de la necesidad de disponer de m\u00faltiples grupos de cient\u00edficos repartidos por el mundo y colaborando entre ellos (envi\u00e1ndose informes, dibujos, esquemas, fotos y todo tipo de documentos) que naci\u00f3 la web.</p> <p>Es en los inicios del protocolo HTTP, a mediados del a\u00f1o 1990, cuando encontramos la versi\u00f3n 0.9. Esta versi\u00f3n ten\u00eda como \u00fanica finalidad transferir datos por Internet en forma de p\u00e1ginas web escritas en lenguaje de marcado de hipertexto (HTML, HyperText Markup Language). A partir de la versi\u00f3n 1.0 del protocolo surgi\u00f3 la posibilidad de transferir mensajes con encabezados que describ\u00edan el contenido de los mensajes.</p>"},{"location":"#versiones","title":"Versiones","text":"<p>La primera versi\u00f3n: HTTP/1</p> <p>La historia de HTTP empez\u00f3 en 1989, cuando Tim Berners-Lee y su equipo del CERN (Suiza) empezaron a desarrollar la World Wide Web. La versi\u00f3n inicial de HTTP fue bautizada con el n\u00famero de versi\u00f3n 0.9, consist\u00eda en una sola l\u00ednea y solo permit\u00eda solicitar un archivo HTML del servidor cada vez.</p> <p>El servidor entonces no hac\u00eda m\u00e1s que transferir el archivo solicitado, de manera que esta versi\u00f3n del protocolo solo pod\u00eda manejar archivos HTML.</p> <p>El primer est\u00e1ndar oficial: HTTP/1.1</p> <p>HTTP/1.1 aclar\u00f3 ambig\u00fcedades y a\u00f1adi\u00f3 numerosas mejoras:</p> <ul> <li>Una conexi\u00f3n pod\u00eda ser reutilizada, ahorrando as\u00ed el tiempo de re-abrirla repetidas veces.</li> <li>Enrutamiento('Pipelining' en ingl\u00e9s) se a\u00f1adi\u00f3 a la especificaci\u00f3n, permitiendo realizar una segunda petici\u00f3n de datos, antes de que fuera respondida la primera, disminuyendo de este modo la latencia de la comunicaci\u00f3n.</li> <li>Se permiti\u00f3 que las respuestas a peticiones, pod\u00edan ser divididas en sub-partes.</li> <li>La negociaci\u00f3n de contenido, incluyendo el lenguaje, el tipo de codificaci\u00f3n, o tipos, se a\u00f1adieron a la especificaci\u00f3n, permitiendo que servidor y cliente, acordasen el contenido m\u00e1s adecuado a intercambiarse.</li> <li>Gracias a la cabecera, Host, pudo ser posible alojar varios dominios en la misma direcci\u00f3n IP.</li> </ul> <p>Un protocolo de mayor rendimiento HTTP/2</p> <p>Seg\u00fan pasaban los a\u00f1os, las p\u00e1ginas web se volv\u00edan cada vez m\u00e1s amplias y complejas. Para cargar una web moderna en el navegador, este tiene que solicitar muchos megabytes de datos y enviar hasta cien solicitudes HTTP. HTTP/1.1 est\u00e1 pensado para procesar solicitudes una tras otra en una misma conexi\u00f3n, de manera que cuanto m\u00e1s compleja sea una p\u00e1gina web, m\u00e1s tardar\u00e1 en cargarse y mostrarse.</p> <p>Por esta raz\u00f3n, Google desarroll\u00f3 un nuevo y experimental protocolo, el SPDY o Speedy, que despert\u00f3 un gran inter\u00e9s entre los desarrolladores y permiti\u00f3 que en 2015 se publicara la versi\u00f3n HTTP/2 del protocolo. Este est\u00e1ndar incluye m\u00faltiples mejoras que tienen como objetivo acelerar la carga de las p\u00e1ginas web.</p> <p>La versi\u00f3n HTTP/2 se extendi\u00f3 r\u00e1pidamente y las p\u00e1ginas web con mucho tr\u00e1fico fueron de las primeras en adoptarla. Actualmente (con fecha de enero de 2020), seg\u00fan W3Techs, un 42 % de las p\u00e1ginas web utilizan la versi\u00f3n HTTP/2.</p> <p>El futuro: HTTP/3</p> <p>Un punto d\u00e9bil de todas las versiones de HTTP usadas hasta ahora es el protocolo de control de transmisi\u00f3n (TCP) en el que se basan. Este protocolo requiere que el receptor de cada paquete de datos confirme la recepci\u00f3n antes de que pueda enviarse el siguiente paquete. De este modo, basta con que se pierda un paquete para que todos los dem\u00e1s tengan que esperar a que dicho paquete sea transmitido de nuevo.</p> <p>Para evitarlos, la nueva versi\u00f3n HTTP/3 no funcionar\u00e1 con TCP, sino con UDP, que no aplica este tipo de medidas correctivas. A partir de UDP, se ha creado el protocolo QUIC (Quick UDP Internet Connections), que ser\u00e1 la base de HTTP/3.</p>"},{"location":"#funcionamiento-del-protocolo-http","title":"Funcionamiento del protocolo HTTP","text":"<p>Ya hemos comentado que el protocolo HTTP tiene un funcionamiento bastante sencillo basado en el env\u00edo de mensajes entre cliente y servidor.</p> <p>Gr\u00e1ficamente podemos resumir el proceso de comunicaci\u00f3n HTTP como sigue:</p> <p></p> <ol> <li> <p>Un usuario accede a una URL, seleccionando un enlace de un documento HTML o introduci\u00e9ndola directamente en el campo correspondiente del cliente Web.</p> </li> <li> <p>El cliente Web descodifica la URL, separando sus diferentes partes: el protocolo de acceso, la direcci\u00f3n DNS o IP del servidor, el posible puerto opcional (el valor por defecto es 80) y el objeto requerido del servidor. <code>http://direccion[:puerto][path]</code></p> </li> </ol> <p>Ejemplo: <code>http://www.miweb.com/documento.html</code></p> <ol> <li> <p>Se abre una conexi\u00f3n TCP/IP con el servidor, llamando al puerto TCP correspondiente. En ese momento, se realiza la petici\u00f3n HTTP. Para ello, se env\u00eda el comando necesario (GET, POST, HEAD,...), la direcci\u00f3n del objeto requerido (el contenido de la URL que sigue a la direcci\u00f3n del servidor), la versi\u00f3n del protocolo HTTP empleada y un conjunto variable de informaci\u00f3n, que incluye datos sobre las capacidades del navegador (browser), datos opcionales para el servidor, etc.</p> </li> <li> <p>El servidor devuelve la respuesta al cliente. Consiste en un c\u00f3digo de estado y el tipo de dato MIME de la informaci\u00f3n de retorno, seguido de la propia informaci\u00f3n.</p> </li> <li> <p>Se cierra la conexi\u00f3n TCP. Este proceso se repite en cada acceso al servidor HTTP. Por ejemplo, si se recoge un documento HTML en cuyo interior est\u00e1n insertadas 2 im\u00e1genes y 1 v\u00eddeo, el proceso anterior se repite cuatro veces, una para el documento HTML y tres m\u00e1s para los recursos (la dos im\u00e1genes y el v\u00eddeo).</p> </li> </ol>"},{"location":"#comandos-o-metodos-http","title":"Comandos o m\u00e9todos HTTP","text":"<p>HTTP define un conjunto de m\u00e9todos de petici\u00f3n para indicar la acci\u00f3n que se desea realizar para un recurso determinado.</p> <p></p> <p>El est\u00e1ndar HTTP/1.0 recoge \u00fanicamente tres comandos, que representan las operaciones de recepci\u00f3n y env\u00edo de informaci\u00f3n y chequeo de estado:</p> <ul> <li> <p>GET: se utiliza para solicitar cualquier tipo de informaci\u00f3n o recurso al servidor. Cada vez que se pulsa sobre un enlace o se teclea directamente a una URL se usa este comando. Como resultado, el servidor HTTP enviar\u00e1 el recurso correspondiente.</p> </li> <li> <p>HEAD: se utiliza para solicitar informaci\u00f3n sobre el recurso: su tama\u00f1o, su tipo, su fecha de modificaci\u00f3n\u2026 Es usado por los gestores de cach\u00e9s de p\u00e1ginas o los servidores proxy, para conocer cu\u00e1ndo es necesario actualizar la copia que se mantiene del recurso. Con HEAD se podr\u00e1 comprobar la \u00faltima fecha de modificaci\u00f3n de un recurso antes de traer una nueva copia del mismo.</p> </li> <li> <p>POST: sirve para enviar informaci\u00f3n al servidor, por ejemplo, los datos contenidos en un formulario. El servidor pasar\u00e1 esta informaci\u00f3n a un proceso encargado de su tratamiento.</p> </li> </ul> <p>La versi\u00f3n 1.1 del protocolo incorpora unos pocos comandos m\u00e1s como son: OPTIONS, PUT, DELETE, TRACE y CONNECT. Veamos algunos de ellos:</p> <ul> <li> <p>OPTIONS: Devuelve los m\u00e9todos HTTP que el servidor soporta para una URL espec\u00edfica. Esto puede ser utilizado para comprobar la funcionalidad de un servidor web mediante petici\u00f3n en lugar de un recurso espec\u00edfico.</p> </li> <li> <p>DELETE: sirve para eliminar un recurso especificado en la URL, aunque pocas veces sera permitido por un servidor web.</p> </li> <li> <p>TRACE: comando que permite hacer un sondeo para saber todos los dispositivos de la red por los que pasa nuestra petici\u00f3n. As\u00ed podremos descubrir si la petici\u00f3n pasa a trav\u00e9s dispositivos intermedios o proxys antes de llegar al servidor Web.</p> </li> <li> <p>PUT: puede verse como el comando inverso a GET. Nos permite escribir datos en el servidor o, lo que es lo mismo, poner un recurso en la URL que se especifique. Si el recurso no existe lo crea sino lo reemplaza. La diferencia con POST puede ser algo confusa; mientras que POST est\u00e1 orientado a la creaci\u00f3n de nuevos contenidos, PUT est\u00e1 m\u00e1s orientado a la actualizaci\u00f3n de los mismos (aunque tambi\u00e9n podr\u00eda crearlos).</p> </li> </ul> <p>HTTP/2 no incluye m\u00e9todos nuevos.</p>"},{"location":"#ejemplo-de-peticion-y-respuesta","title":"Ejemplo de petici\u00f3n y respuesta","text":"<p>Una solicitud HTTP es un conjunto de l\u00edneas que el navegador env\u00eda al servidor. Incluye:</p> <ul> <li>El recurso solicitado, el m\u00e9todo que se aplicar\u00e1 y la versi\u00f3n del protocolo utilizada.</li> <li>Los campos del encabezado de solicitud: es un conjunto de l\u00edneas opcionales que permiten aportar informaci\u00f3n adicional sobre la solicitud y/o el cliente (navegador, sistema operativo, etc.). Cada una de estas l\u00edneas est\u00e1 formada por un nombre que describe el tipo de encabezado, seguido de dos puntos (:) y el valor del encabezado.</li> <li>El cuerpo de la solicitud: es un conjunto de l\u00edneas opcionales que deben estar separadas de las l\u00edneas precedentes por una l\u00ednea en blanco y que, por ejemplo, permiten la transmisi\u00f3n de datos al servidor de un formulario a trav\u00e9s del m\u00e9todo POST.</li> </ul> <p></p> <ul> <li>Una l\u00ednea de estado donde figura el versi\u00f3n del protocolo usada, un c\u00f3digo de estado/error y un texto con el significado de dicho c\u00f3digo.</li> <li>Los posibles c\u00f3digos de estado se identifican con n\u00fameros de tres cifras y se clasifican en cinco grupos seg\u00fan sean informativos (1xx), de \u00e9xito en la solicitud (2xx), para redireccionar la solicitud (3xx), por error generado en el cliente (4xx) o bien por errores generados en el servidor (5xx) \u2192 C\u00f3digos de estado/error.</li> <li>Los campos del encabezado de la respuesta. Conjunto de lineas opcionales que aportan informaci\u00f3n adicional sobre la respuesta y/o el servidor.</li> <li>El cuerpo de la respuesta que contiene el recurso (objeto) solicitado</li> </ul>"},{"location":"practica1/","title":"Pr\u00e1ctica 2.1","text":""},{"location":"practica1/#instalacion-servidor-web-nginx","title":"Instalaci\u00f3n servidor web Nginx","text":"<p>Para instalar el servidor nginx en nuestra Debian, primero actualizamos  los repositorios y despu\u00e9s instalamos el paquete correspondiente:</p> <p><code>sudo apt update</code> <code>sudo apt install nginx</code></p> <p></p> <p>Comprobamos que nginx se ha instalado y que est\u00e1 funcionando correctamente:</p> <p><code>systemctl status nginx</code></p> <p></p>"},{"location":"practica1/#creacion-de-las-carpeta-del-sitio-web","title":"Creaci\u00f3n de las carpeta del sitio web","text":"<p>Igual que ocurre en Apache, todos los archivos que formar\u00e1n parte de un sitio web que servir\u00e1 nginx se organizar\u00e1n en carpetas. Estas carpetas, t\u00edpicamente est\u00e1n dentro de /var/www.</p> <p>As\u00ed pues, vamos a crear la carpeta de nuestro sitio web o dominio:</p> <p><code>sudo mkdir -p /var/www/nombre_web/html</code></p> <p></p> <p>Dentro de esa carpeta html, deb\u00e9is clonar el siguiente repositorio:</p> <p><code>https://github.com/cloudacademy/static-website-example</code></p> <p></p> <p>Adem\u00e1s, haremos que el propietario de esta carpeta y todo lo que haya dentro  sea el usuario www-data, t\u00edpicamente el usuario del servicio web.</p> <p><code>sudo chown -R www-data:www-data /var/www/nombre_web/html</code></p> <p></p> <p>Y le daremos los permisos adecuados para que no nos de un error de acceso  no autorizado al entrar en el sitio web:</p> <p><code>sudo chmod -R 755 /var/www/nombre_web</code></p> <p></p> <p>Para comprobar que el servidor est\u00e1 funcionando y sirviendo p\u00e1ginas  correctamente, pod\u00e9is acceder desde vuestro cliente a:</p> <p><code>http://IP-maq-virtual</code></p> <p></p> <p>Y os deber\u00e1 aparecer algo as\u00ed:</p> <p></p> <p>Lo que demuestra que todo es correcto hasta ahora.</p>"},{"location":"practica1/#configuracion-de-servidor-web-nginx","title":"Configuraci\u00f3n de servidor web NGINX","text":"<p>En Nginx hay dos rutas importantes. La primera de ellas es sites-available, que contiene los archivos de configuraci\u00f3n de los hosts virtuales o bloques disponibles en el servidor. Es decir, cada uno de los sitios webs que alberga el servido. La otra es sites-enabled, que contiene los archivos de configuraci\u00f3n de los sitios habilitados, es decir, los que funcionan en ese momento.</p> <p>Dentro de sites-available hay un archivo de configuraci\u00f3n por defecto (default), que es la p\u00e1gina que se muestra si accedemos al servidor sin indicar ning\u00fan sitio web o cuando el sitio web no es encontrado en el servidor (debido a una mala configuraci\u00f3n por ejemplo). Esta es la p\u00e1gina que nos ha aparecido en el apartado anterior.</p> <p>Para que Nginx presente el contenido de nuestra web, es necesario crear un bloque de servidor con las directivas correctas. En vez de modificar el archivo de configuraci\u00f3n predeterminado directamente, crearemos uno nuevo en /etc/nginx/sites-available/nombre_web:</p> <p><code>sudo nano /etc/nginx/sites-available/vuestro_dominio</code></p> <p></p> <p>Y el contenido de ese archivo de configuraci\u00f3n:</p> <pre><code>server {\n        listen 80;\n        listen [::]:80;\n        root /ruta/absoluta/archivo/index;\n        index index.html index.htm index.nginx-debian.html;\n        server_name nombre_web;\n        location / {\n                try_files $uri $uri/ =404;\n        }\n}\n</code></pre> <p></p> <p>Aqu\u00ed la directiva root debe ir seguida de la ruta absoluta absoluta d\u00f3nde se encuentre el archivo index.html de nuestra p\u00e1gina web, que se encuentra entre todos los que hab\u00e9is descomprimido.</p> <p>Y crearemos un archivo simb\u00f3lico entre este archivo y el de sitios que est\u00e1n habilitados, para que se d\u00e9 de alta autom\u00e1ticamente.</p> <p><code>sudo ln -s /etc/nginx/sites-available/nombre_web /etc/nginx/sites-enabled/</code></p> <p></p> <p>Y reiniciamos el servidor para aplicar la configuraci\u00f3n:</p> <p><code>sudo systemctl restart nginx</code></p> <p></p>"},{"location":"practica1/#comprobaciones","title":"Comprobaciones","text":""},{"location":"practica1/#comprobacion-del-correcto-funcionamiento","title":"Comprobaci\u00f3n del correcto funcionamiento","text":"<p>Como a\u00fan no poseemos un servidor DNS que traduzca los nombres a IPs, debemos hacerlo de forma manual. Vamos a editar el archivo /etc/hosts de nuestra m\u00e1quina anfitriona para que asocie la IP de la m\u00e1quina virtual, a nuestro server_name.</p> <p>Este archivo, en Linux, est\u00e1 en: <code>/etc/hosts</code></p> <p>Y en Windows: <code>C:\\Windows\\System32\\drivers\\etc\\hosts</code></p> <p>Y deberemos a\u00f1adirle la l\u00ednea:</p> <p><code>192.168.X.X nombre_web</code></p> <p></p> <p>donde deb\u00e9is sustituir la IP por la que tenga vuestra m\u00e1quina virtual.</p>"},{"location":"practica1/#comprobar-registros-del-servidor","title":"Comprobar registros del servidor","text":"<p>Comprobad que las peticiones se est\u00e1n registrando correctamente en los archivos de logs, tanto las correctas como las err\u00f3neas:  - /var/log/nginx/access.log: cada solicitud a su servidor web se registra en este archivo de registro, a menos que Nginx est\u00e9 configurado para hacer algo diferente.  - /var/log/nginx/error.log: cualquier error de Nginx se asentar\u00e1 en este registro</p> <p>\u2139\ufe0f Informaci\u00f3n: Si no os aparece nada en los logs, podr\u00eda pasar que el navegador ha cacheado la p\u00e1gina web y que, por tanto, ya no est\u00e1 obteniendo la p\u00e1gina del navegador sino de la propia memoria. Para solucionar esto, pod\u00e9is acceder con el modo privado del navegador y ya os deber\u00eda registrar esa actividad en los logs.</p>"},{"location":"practica1/#ftp","title":"FTP","text":"<p>Si queremos tener varios dominios o sitios web en el mismo servidor nginx (es decir, que tendr\u00e1n la misma IP) debemos repetir todo el proceso anterior con el nuevo nombre de dominio que queramos configurar.</p>"},{"location":"practica1/#como-transferir-archivos-desde-nuestra-maquina-localanfitrion-a-nuestra-maquina-virtual-debianservidor-remoto","title":"\u00bfC\u00f3mo transferir archivos desde nuestra m\u00e1quina local/anfitri\u00f3n a nuestra m\u00e1quina virtual Debian/servidor remoto?","text":"<p>A d\u00eda de hoy el proceso m\u00e1s sencillo y seguro es a trav\u00e9s de Github como hemos visto antes. No obstante, el curr\u00edculum de la Conseller\u00eda d'Educaci\u00f3 me obliga a ense\u00f1aros un m\u00e9todo un tanto obsoleto a d\u00eda de hoy, as\u00ed que vamos a ello, os presento al FTP.</p> <p>El FTP es un protocolo de transferencia de archivos entre sistemas conectados a una red TCP. Como su nombre indica, se trata de un protocolo que permite transferir archivos directamente de un dispositivo a otro. Actualmente, es un protocolo que poco a poco va abandon\u00e1ndose, pero ha estado vigente m\u00e1s de 50 a\u00f1os.</p> <p>El protocolo FTP tal cual es un protocolo inseguro, ya que su informaci\u00f3n no viaja cifrada. Sin embargo, en 2001 esto se solucion\u00f3 con el protocolo SFTP, que le a\u00f1ade una capa SSH para hacerlo m\u00e1s seguro y privado.</p> <p>SFTP no es m\u00e1s que el mismo protocolo FTP pero implementado por un canal seguro. Son las siglas de SSH File Transfer Protocol y consiste en una extensi\u00f3n de Secure Shell Protocol (SSH) creada para poder hacer transmisiones de archivos.</p> <p>La seguridad que nos aporta SFTP es importante para la transferencia de archivos porque, si no disponemos de ella, los archivos viajar\u00e1n tal cual por la red, sin ning\u00fan tipo de encriptaci\u00f3n. As\u00ed pues, usando FTP tradicional, si alg\u00fan agente consigue escuchar las transferencias, podr\u00eda ocurrir que la informaci\u00f3n quedase al descubierto. Esto ser\u00eda especialmente importante si los archivos que subimos contienen informaci\u00f3n confidencial o datos personales.</p> <p>Dado que usar SFTP aporta mayor seguridad a las transmisiones, es recomendable utilizarlo, m\u00e1s a\u00fan sabiendo que realmente no hay mucha dificultad en establecer las conexiones por el protocolo seguro.</p>"},{"location":"practica1/#configurar-servidor-sftp-en-debian","title":"Configurar servidor SFTP en Debian","text":"<p>En primer lugar, lo instalaremos desde los repositorios:</p> <pre><code>sudo apt-get update\nsudo apt-get install vsftpd\n</code></pre> <p> </p> <p>Ahora vamos a crear una carpeta en nuestro home en Debian:</p> <p><code>mkdir /home/nombre_usuario/ftp</code></p> <p></p> <p>En la configuraci\u00f3n de vsftpd indicaremos que este ser\u00e1 el directorio al cual vsftpd se cambia despu\u00e9s de conectarse el usuario.</p> <p>Ahora vamos a crear los certificados de seguridad necesarios para aportar la capa de cifrado a nuestra conexi\u00f3n (algo parecido a HTTPS)</p> <p><code>sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/ssl/private/vsftpd.pem -out /etc/ssl/private/vsftpd.pem</code></p> <p> </p> <p>Y una vez realizados estos pasos, procedemos a realizar la configuraci\u00f3n de vsftpd propiamente dicha. Se trata, con el editor de texto que m\u00e1s os guste, de editar el archivo de configuraci\u00f3n de este servicio, por ejemplo con nano:</p> <p><code>sudo nano /etc/vsftpd.conf</code></p> <p></p> <p>En primer lugar, buscaremos las siguientes l\u00edneas del archivo y las eliminaremos por completo:</p> <pre><code>rsa_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem\nrsa_private_key_file=/etc/ssl/private/ssl-cert-snakeoil.key\nssl_enable=NO\n</code></pre> <p>Tras ello, a\u00f1adiremos estas l\u00edneas en su lugar</p> <pre><code>rsa_cert_file=/etc/ssl/private/vsftpd.pem\nrsa_private_key_file=/etc/ssl/private/vsftpd.pem\nssl_enable=YES\nallow_anon_ssl=NO\nforce_local_data_ssl=YES\nforce_local_logins_ssl=YES\nssl_tlsv1=YES\nssl_sslv2=NO\nssl_sslv3=NO\nrequire_ssl_reuse=NO\nssl_ciphers=HIGH\n\nlocal_root=/home/nombre_usuario/ftp\n</code></pre> <p></p> <p>Y, tras guardar los cambios, reiniciamos el servicio para que coja la nueva configuraci\u00f3n:</p> <p><code>sudo systemctl restart --now vsftpd</code></p> <p></p> <p>Tras acabar esta configuraci\u00f3n, ya podremos acceder a nuestro servidor mediante un cliente FTP adecuado, como por ejemplo Filezilla de dos formas, a saber: - Mediante el puerto por defecto del protocolo inseguro FTP, el 21, pero utilizando certificados que cifran el intercambio de datos convirti\u00e9ndolo as\u00ed en seguro - Haciendo uso del protocolo SFTP, dedicado al intercambio de datos mediante una conexi\u00f3n similar a SSH, utilizando de hecho el puerto 22.</p> <p>Tras descargar el cliente FTP en nuestro ordenador, introducimos los datos necesarios para conectarnos a nuestro servidor FTP en Debian:</p> <p></p> <ul> <li>La IP de Debian</li> <li>El nombre de usuario de Debian</li> <li>La contrase\u00f1a de ese usuario </li> <li>El puerto de conexi\u00f3n, que ser\u00e1 el 21 para conectarnos utilizando los certificados generados previamente</li> </ul> <p>Tras darle al bot\u00f3n de Conexi\u00f3n r\u00e1pida, nos saltar\u00e1 un aviso a prop\u00f3sito del certificado, le damos a aceptar puesto que no entra\u00f1a peligro ya que lo hemos genrado nosotros mismos:</p> <p></p> <p>Nos conectaremos directamente a la carpeta que le hab\u00edamos indicado en el archivo de configuraci\u00f3n /home/raul/ftp</p> <p>Una vez conectados, buscamos la carpeta de nuestro ordenador donde hemos descargado el .zip (en la parte izquierda de la pantalla) y en la parte derecha de la pantalla, buscamos la carpeta donde queremos subirla. Con un doble click o utilizando bot\u00f3n derecho &gt; subir, la subimos al servidor.</p> <p></p> <p>Si lo que quisi\u00e9ramos es conectarnos por SFTP, exactamente igual de v\u00e1lido, har\u00edamos:</p> <p>Fij\u00e1os que al utilizar las claves de SSH que ya estamos utilizando desde la Pr\u00e1ctica 1, no se debe introducir la contrase\u00f1a, \u00fanicamente el nombre de usuario.</p> <p>Puesto que nos estamos conectando usando las claves FTP, nos sale el mismo aviso que nos sal\u00eda al conectarnos por primera vez por SSH a nuestra Debian, que aceptamos porque sabemos que no entra\u00f1a ning\u00fan peligro en este caso:</p> <p></p> <p></p> <p>Y vemos que al ser una especie de conexi\u00f3n SSH, nos conecta al home del usuario, en lugar de a la carpeta ftp. A partir de aqu\u00ed ya proceder\u00edamos igual que en el otro caso.</p> <p>Recordemos que debemos tener nuestro sitio web en la carpeta /var/www y darle los permisos adecuados, de forma similiar a c\u00f3mo hemos hecho con el otro sitio web.</p> <p>El comando que nos permite descomprimir un .zip en un directorio concreto es:</p> <p><code>unzip archivo.zip -d /nombre/directorio</code></p> <p></p> <p>Si no tuvier\u00e1is unzip instalado, lo instal\u00e1is:</p> <p><code>sudo apt-get update &amp;&amp; sudo apt-get install unzip</code></p>"},{"location":"practica1/#https","title":"HTTPS","text":"<p>En este apartado le a\u00f1adiremos a nuestro servidor una capa de seguridad necesaria. Haremos que todos nuestros sitios web alojados hagan uso de certificados SSL y se acceda a ellos por medio de HTTPS.</p> <p>Para ello, a modo de prueba de concepto, nos generaremos unos certificados autofirmados y, en el fichero de configuraci\u00f3n de nuestros hosts virtuales (los sitios web que hemos configurado), deberemos cambiar los par\u00e1metros necesarios.</p> <p>Apoyaos en una b\u00fasqueda en Internet para conseguir vuestro objetivo.</p>"},{"location":"practica1/#redireccion-http-a-https","title":"Redirecci\u00f3n HTTP a HTTPS","text":"<p>Cuando hay\u00e1is cumplido con la tarea de dotar de HTTPS a vuestros sitios web, podr\u00e9is pasar a esta.</p> <p>Fij\u00e1os que con el estado de la configuraci\u00f3n actual, a vuestro sitio web se puede acceder a\u00fan de dos formas simult\u00e1neas, por el puerto 80 (HTTP e inseguro) y por el puerto 443 (HTTPS, seguro). Puesto que queremos dejar la configuraci\u00f3n bien hecha y sin posibles fisuras, vuestro objetivo es que si el usuario accede a vuestro sitio web mediante el puerto 80 (HTTP) autom\u00e1ticamente, por motivos de seguridad, se le redirija a HTTPS, en el puerto 443.</p> <p>Realizad la b\u00fasqueda de informaci\u00f3n adecuada para conseguir esta redirecci\u00f3n autom\u00e1tica mediante los cambios necesarios en vuestros archivos de hosts virtuales.</p> <p>Primero que nada entraremos en el archivo:</p> <p><code>sudo nano /etc/nginx/sites-available/practicadaw</code></p> <p></p> <p>Editar el script que hab\u00eda antes:</p> <pre><code>server {\n    listen 80;\n    listen [::]:80;\n    server_name practicadaw;\n\n    return 301 https://$server_name$request_uri;\n}\n</code></pre> <p>y a\u00f1adir debajo:</p> <pre><code>server {\n    listen 443 ssl;\n    listen [::]:443 ssl;\n    server_name practicadaw;\n\n    ssl_certificate /etc/ssl/certs/nginx-selfsigned.crt;\n    ssl_certificate_key /etc/ssl/private/nginx-selfsigned.key;\n\n    root /var/www/practicadaw/html/static-website-example/;\n    index index.html index.htm index.nginx-debian.html;\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre> <p></p> <p>Finalmente comprobamos que se nos abra la web y muestre este mensaje. Tras esto ya tendremos nuestra web con nginx desplegada.</p> <p></p>"},{"location":"practica1/#cuestiones-finales","title":"Cuestiones finales","text":""},{"location":"practica1/#cuestion-1","title":"\ud83d\udfe6 Cuesti\u00f3n 1","text":"<p>\u00bfQu\u00e9 pasa si no hago el link simb\u00f3lico entre <code>sites-available</code> y <code>sites-enabled</code> de mi sitio web?</p> <p>Si no haces el enlace simb\u00f3lico entre <code>sites-available</code>y <code>sites-enabled</code></p> <ul> <li>Provocar\u00e1s que tu sitio no est\u00e9 activo, produciendo errores de acceso (como 404)</li> <li>Aunque hayas hecho la configuraci\u00f3n de <code>sites-available</code>, el servidor no las reconocer\u00e1.</li> <li>Hay riesgo de errores en la configuraci\u00f3n que podr\u00edan dar la impresi\u00f3n de que el servidor est\u00e1 funcionando despu\u00e9s de reiniciarse o recargarse, cuando en realidad no lo est\u00e1.</li> <li>Pueden haber problemas en la administraci\u00f3n de sitios por la dificultad a la hora de gestionar varias configuraciones de sitios, ya que no es posible habilitar o deshabilitar un sitio de manera f\u00e1cil al agregar o eliminar el enlace en sites-enabled.</li> </ul>"},{"location":"practica1/#cuestion-2","title":"\ud83d\udfe6 Cuesti\u00f3n 2","text":"<p>\u00bfQu\u00e9 pasa si no le doy los permisos adecuados a <code>/var/www/nombre_web</code>?</p> <ul> <li>El servidor web no podr\u00e1 leer los archivos.</li> <li>Si el sitio necesita escribir archivos fallar\u00e1 si no tiene permisos de escritura.</li> <li>Otros usuarios o servicios que dependan de esos archivos no podr\u00e1n acceder.</li> </ul>"},{"location":"practica2/","title":"Pr\u00e1ctica 2.2","text":""},{"location":"practica2/#requisitos-antes-de-comenzar-la-practica","title":"Requisitos antes de comenzar la pr\u00e1ctica","text":"<p>[!WARNING] </p> <ul> <li>La pr\u00e1ctica 2.1 ha de estar funcionando correctamente.</li> <li>No empezar la pr\u00e1ctica antes de tener la 2.1 funcionando y comprobada.</li> </ul>"},{"location":"practica2/#introduccion","title":"Introducci\u00f3n","text":"<p>En el contexto de una transacci\u00f3n HTTP, la autenticaci\u00f3n de acceso b\u00e1sica es un m\u00e9todo dise\u00f1ado para permitir a un navegador web, u otro programa cliente, proveer credenciales en la forma de usuario y contrase\u00f1a cuando se le solicita una p\u00e1gina al servidor.</p> <p>La autenticaci\u00f3n b\u00e1sica, como su nombre lo indica, es la forma m\u00e1s b\u00e1sica de autenticaci\u00f3n disponible para las aplicaciones Web. Fue definida por primera vez en la especificaci\u00f3n HTTP en s\u00ed y no es de ninguna manera elegante, pero cumple su funci\u00f3n.</p> <p>Este tipo de autenticaci\u00f3n es el tipo m\u00e1s simple disponible pero adolece de importantes problemas de seguridad que no la hacen recomendable en muchas situaciones. No requiere el uso ni de cookies, ni de identificadores de sesi\u00f3n, ni de p\u00e1gina de ingreso.</p>"},{"location":"practica2/#paquetes-necesarios","title":"Paquetes necesarios","text":"<p>Para esta pr\u00e1ctica podemos utilizar la herramienta openssl para crear las contrase\u00f1as.</p> <p>En primer lugar debemos comprobar si el paquete est\u00e1 instalado:</p> <p><code>dpkg -l | grep openssl</code></p> <p> Y si no lo estuviera, instalarlo.</p>"},{"location":"practica2/#creacion-de-usuarios-y-contrasenas-para-el-acceso-web","title":"Creaci\u00f3n de usuarios y contrase\u00f1as para el acceso web","text":"<p>Crearemos un archivo oculto llamado \u201c.htpasswd\u201d en el directorio de configuraci\u00f3n /etc/nginx donde guardar nuestros usuarios y contrase\u00f1as (la -c es para crear el archivo):</p> <p><code>sudo sh -c \"echo -n 'vuestro_nombre:' &gt;&gt; /etc/nginx/.htpasswd\"</code></p> <p></p> <p>Ahora crearemos un password cifrado para el usuario:</p> <p><code>sudo sh -c \"openssl passwd -apr1 &gt;&gt; /etc/nginx/.htpasswd\"</code></p> <p></p> <p>Este proceso se podr\u00e1 repetir para tantos usuarios como haga falta.</p> <ul> <li>Crea dos usuarios, uno con tu nombre y otro con tu primer apellido</li> <li>Comprueba que el usuario y la contrase\u00f1a aparecen cifrados en el fichero:</li> </ul> <p><code>cat /etc/nginx/.htpasswd</code></p> <p></p>"},{"location":"practica2/#configurando-el-servidor-nginx-para-usar-autenticacion-basica","title":"Configurando el servidor Nginx para usar autenticaci\u00f3n b\u00e1sica","text":"<p>Editaremos la configuraci\u00f3n del server block sobre el cual queremos aplicar la restricci\u00f3n de acceso. Utilizaremos para esta autenticaci\u00f3n el sitio web de Perfect Learn:</p> <p>[!NOTE]Info Recuerda que un server block es cada uno de los dominios (<code>server {...}</code> dentro del archivo de configuraci\u00f3n) de alguno de los sitios web que hay en el seridor.</p> <p><code>sudo nano /etc/nginx/sites-available/nombre_web</code></p> <p></p> <p></p> <p>Una vez terminada la configuraci\u00f3n, reiniciamos el servicio para que aplique nuestra pol\u00edtica de acceso.</p> <p><code>sudo systemctl restart nginx</code></p> <p></p> <p>\ud83d\udfe6 Comprobaci\u00f3n 1</p> <p>Comprueba desde tu m\u00e1quina f\u00edsica que puedes acceder al sitio web y que se te solicita autenticaci\u00f3n.</p> <p></p> <p>\ud83d\udfe6 Comprobaci\u00f3n 2</p> <p>Comprueba que si decides cancelar la autenticaci\u00f3n, se te negar\u00e1 el acceso al sitio con un error. \u00bfQu\u00e9 error es?</p> <p></p>"},{"location":"practica2/#tareas","title":"Tareas","text":"<p>\ud83d\udfe9 Tarea 1</p> <ul> <li> <p>Intenta entrar primero con un usuario err\u00f3neo y luego con otro correcto. Puedes ver todos los sucesos y registros en los logs access.log y error.log</p> </li> <li> <p>Adjunta una captura de pantalla de los logs donde se vea que intentas entrar primero con un usuario inv\u00e1lido y con otro v\u00e1lido. Indica d\u00f3nde podemos ver los errores de usuario inv\u00e1lido o no encontrado, as\u00ed como donde podemos ver el n\u00famero de error que os aparec\u00eda antes</p> </li> </ul> <p></p> <p></p> <p></p> <p>Cuando hemos configurado el siguiente bloque:</p> <pre><code>location / {\n        auth_basic  \"\u00c0rea restringida\";\n        auth_basic_user_file    /etc/nginx/.htpasswd;\n            try_files $uri $uri/ =404;\n        }\n</code></pre> <p>La autenticaci\u00f3n se aplica al directorio/archivo que le indicamos en la declaraci\u00f3n del location y que en este caso el ra\u00edz /.</p> <p>As\u00ed pues, esta restricci\u00f3n se aplica al directorio ra\u00edz o base donde residen los archivos del sitio web y que es en mi caso:</p> <p><code>/var/www/practicadaw/html/simple-static-website</code></p> <p>Y a todos los archivos que hay dentro, ya que no hemos especificado ninguno en concreto.</p> <p>Ahora bien, vamos a probar a aplicar autenticaci\u00f3n s\u00f3lo a una parte de la web. Vamos a intentar que s\u00f3lo se necesite autenticac\u00ed\u00f3n para entrar a la parte de portfolio:</p> <p>Esta secci\u00f3n se corresponde con el archivo <code>contact.html</code> dentro del directorio ra\u00edz.</p> <p>\ud83d\udfe9 Tarea 2</p> <p>Borra las dos l\u00edneas que hacen referencia a la autenticaci\u00f3n b\u00e1sica en el location del direectorio ra\u00edz. Tras ello, a\u00f1ade un nuevo location debajo con la autenticaci\u00f3n b\u00e1sica para el archivo/secci\u00f3n <code>contacto.html</code> unicamente.</p> <p>[!WARNING] Warning</p> <p>Fijaos que deb\u00e9is tener cuidado porque la \u00faltima l\u00ednea del archivo ha de ser <code>}</code> que cierra la primera l\u00ednea <code>server {</code> del archivo.</p> <p></p>"},{"location":"practica2/#combinacion-de-la-autenticacion-basica-con-la-restriccion-de-acceso-por-ip","title":"Combinaci\u00f3n de la autenticaci\u00f3n b\u00e1sica con la restricci\u00f3n de acceso por IP","text":"<p>La autenticaci\u00f3n b\u00e1sica HTTP puede ser combinada de forma efectiva con la restricci\u00f3n de acceso por direcci\u00f3n IP. Se pueden implementar dos escenario:</p> <ul> <li>Un usuario debe estar ambas cosas, autenticado y tener una IP v\u00e1lida</li> <li>Un usuario debe o bien estar autenticado, o bien tener una IP v\u00e1lida</li> </ul> <p>Veamos c\u00f3mo lo har\u00edamos:</p> <ol> <li>Como permitir o denegar acceso sobre una IP concreta (directivas allow y deny, respectivamente). Dentro del block server o archivo de configuraci\u00f3n del dominio web, que recordad est\u00e1 en el directorio sites-available:</li> </ol> <p> </p> <pre><code>El acceso se garantizar\u00e1 a la IP 192.168.1.1/24, excluyendo a la direcci\u00f3n 192.168.1.\n\nHay que tener en cuenta que las directivas allow y deny se ir\u00e1n aplicando en el orden en el que aparecen el archivo.\n\nAqu\u00ed aplican sobre la location /api (esto es s\u00f3lo un ejemplo de un hipot\u00e9tico directorio o archivo), pero podr\u00edan aplicar sobre cualquiera, incluida todo el sitio web, la location ra\u00edz /.\n\nLa \u00faltima directiva deny all quiere decir que por defecto denegaremos el acceso a todo el mundo. Por eso hay que poner los allow y deny m\u00e1s espec\u00edficos justo antes de esta, porque al evaluarse en orden de aparici\u00f3n, si los pusi\u00e9ramos debajo se denegar\u00eda el acceso a todo el mundo, puesto que deny all ser\u00eda lo primero que se evaluar\u00eda.\n</code></pre> <ol> <li> <p>Combinar la restricci\u00f3n IP y la autenticaci\u00f3n HTTP con la directiva satisfy.</p> <p>Si establecemos el valor de la directiva a \u201call\u201d, el acceso se permite si el cliente satisface ambas condiciones (IP y usario v\u00e1lido). Si lo establecemos a \u201cany\u201d, el acceso se permite si se satisface al menos una de las dos condiciones.</p> <p></p> </li> </ol>"},{"location":"practica2/#tareas_1","title":"Tareas","text":"<p>\ud83d\udfe9 Tarea 1</p> <p>Configura Nginx para que no deje acceder con la IP de la m\u00e1quina anfitriona al directorio ra\u00edz de una de tus dos webs. Modifica su server block o archivo de configuraci\u00f3n. Comprueba como se deniega el acceso: </p> <ul> <li>Muestra la p\u00e1gina de error en el navegador</li> </ul> <p></p> <p></p> <ul> <li>Muestra el mensaje de error de error.log</li> </ul> <p></p> <p>\ud83d\udfe9 Tarea 2</p> <p>Configura Nginx para que desde tu m\u00e1quina anfitriona se tenga que tener tanto una IP v\u00e1lida como un usuario v\u00e1lido, ambas cosas a la vez, y comprueba que s\u00ed puede acceder sin problemas.</p> <p></p> <ul> <li>Error al intentar acceder desde el m\u00f3vil o con usuario incorrecto.</li> </ul> <p></p> <ul> <li>Acceso con IP y usuario v\u00e1lidos </li> </ul> <p></p>"},{"location":"practica2/#cuestiones-finales","title":"Cuestiones finales","text":"<p>\ud83d\udfe6 Cuesti\u00f3n 1</p> <p>Supongamos que yo soy el cliente con la IP 172.1.10.15 e intento acceder al directorio <code>web_muy_guay</code> de mi sitio web, equivoc\u00e1ndome al poner el usuario y contrase\u00f1a. \u00bfPodr\u00e9 acceder?\u00bfPor qu\u00e9?</p> <p><code>code location /web_muy_guay {    #...    satisfy all;        deny  172.1.10.6;    allow 172.1.10.15;    allow 172.1.3.14;    deny  all;    auth_basic \"Cuesti\u00f3n final 1\";    auth_basic_user_file conf/htpasswd;  }</code></p> <p>No podr\u00e1s acceder ya que al haber puesto <code>satisfy all</code> est\u00e1s pidiendo que se cumplan ambas condiciones, tanto IP permitida como una autenticaci\u00f3n correcta.</p> <p>\ud83d\udfe6 Cuesti\u00f3n 2</p> <p>ask \"Cuesti\u00f3n 1\" Supongamos que yo soy el cliente con la IP 172.1.10.15 e intento acceder al directorio <code>web_muy_guay</code> de mi sitio web, introduciendo correctamente usuario y contrase\u00f1a. \u00bfPodr\u00e9 acceder?\u00bfPor qu\u00e9?</p> <pre><code>location /web_muy_guay {\n    #...\n    satisfy all;    \n    deny  all;\n    deny  172.1.10.6;\n    allow 172.1.10.15;\n    allow 172.1.3.14;\n    auth_basic \"Cuesti\u00f3n final 2: The revenge\";\n    auth_basic_user_file conf/htpasswd;\n}\n</code></pre> <p>Si introduces correctamente el usuario y la contrase\u00f1a, podr\u00e1s acceder al sitio porque cumples ambas condiciones: autenticaci\u00f3n v\u00e1lida y tu IP est\u00e1 en la lista permitida.</p> <p>\ud83d\udfe6 Cuesti\u00f3n 3</p> <p>Supongamos que yo soy el cliente con la IP 172.1.10.15 e intento acceder al directorio web_muy_guay de mi sitio web, introduciendo correctamente usuario y contrase\u00f1a. \u00bfPodr\u00e9 acceder?\u00bfPor qu\u00e9? </p> <pre><code>location /web_muy_guay {\n    #...\n    satisfy any;    \n    deny  172.1.10.6;\n    deny 172.1.10.15;\n    allow 172.1.3.14;\n\n    auth_basic \"Cuesti\u00f3n final 3: The final combat\";\n    auth_basic_user_file conf/htpasswd;\n}\n</code></pre> <p>En este caso, con <code>satisfy any</code>, aunque tu IP est\u00e1 bloqueada, no podr\u00e1s acceder a la web porque se est\u00e1 aplicando una restricci\u00f3n de IP despu\u00e9s que tiene prioridad.</p> <p>\ud83d\udfe6 Cuesti\u00f3n 4</p> <p>A lo mejor no sab\u00e9is que tengo una web para documentar todas mis excursiones espaciales con Jeff, es esta: Jeff Bezos y yo</p> <p>Supongamos que quiero restringir el acceso al directorio de proyectos porque es muy secreto, eso quiere decir a\u00f1adir autenticaci\u00f3n b\u00e1sica a la URL:Proyectos</p> <p>Completa la configuraci\u00f3n para conseguirlo: </p> <pre><code>server {\n        listen 80;\n        listen [::]:80;\n        root /var/www/freewebsitetemplates.com/preview/space-science;\n        index index.html index.htm index.nginx-debian.html;\n        server_name freewebsitetemplates.com www.freewebsitetemplates.com;\n        location              {\n\n            try_files $uri $uri/ =404;\n        }\n    }\n</code></pre> <p>El c\u00f3digo completo con los requisitos ser\u00eda algo como:</p> <pre><code>server {\n    listen 80;\n    listen [::]:80;\n    root /var/www/freewebsitetemplates.com/preview/space-science;\n    index index.html index.htm index.nginx-debian.html;\n    server_name freewebsitetemplates.com www.freewebsitetemplates.com;\n    location /proyectos {\n        auth_basic \"Proyectos secretos\";\n        auth_basic_user_file /etc/nginx/.htpasswd;\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre>"},{"location":"practica3/","title":"Pr\u00e1ctica 2.3","text":"<p>[!WARNING] Atenci\u00f3n</p> <p>Estos apuntes siguen aqu\u00ed para temas de consulta pero a d\u00eda de hoy tiene ciertas partes que pueden haberse quedado obsoletas (Heroku por ejemplo ahora es de pago), los ir\u00e9 actualizando en la medida que el tiempo me lo permita en esta nueva p\u00e1gina. </p>"},{"location":"practica3/#requisitos-antes-de-comenzar-la-practica","title":"Requisitos antes de comenzar la pr\u00e1ctica","text":"<p>[!WARNING] Atenci\u00f3n, importante antes de comenzar</p> <ul> <li> <p>La pr\u00e1ctica 2.1 ha de estar funcionando correctamente</p> </li> <li> <p>No comenzar la pr\u00e1ctica antes de tener la 2.1 funcionando y comprobada</p> </li> </ul>"},{"location":"practica3/#introduccion","title":"Introducci\u00f3n","text":""},{"location":"practica3/#que-es-un-servidor-proxy","title":"\u00bfQu\u00e9 es un servidor proxy?","text":"<p>Un proxy de reenv\u00edo, a menudo llamado proxy, servidor proxy o proxy web, es un servidor que se encuentra frente a un grupo de m\u00e1quinas cliente. Cuando esas m\u00e1quinas realizan solicitudes a sitios y servicios en Internet, el servidor proxy intercepta esas solicitudes y luego se comunica con los servidores web en nombre de esos clientes, como un intermediario.</p> <p>Por ejemplo, tomemos como ejemplo 3 m\u00e1quinas involucradas en una comunicaci\u00f3n t\u00edpica de proxy de reenv\u00edo:</p> <ul> <li> <p>A: Esta es la m\u00e1quina del hogar de un usuario.</p> </li> <li> <p>B: este es un servidor proxy de reenv\u00edo</p> </li> <li> <p>C: este es el servidor de origen de un sitio web (donde se almacenan los datos del sitio web)</p> </li> </ul> <p></p> <p>En una comunicaci\u00f3n est\u00e1ndar por Internet, la m\u00e1quina A se comunicar\u00eda directamente con la m\u00e1quina C, con el cliente enviando solicitudes al servidor de origen y el servidor de origen respondiendo al cliente. Cuando hay un proxy de reenv\u00edo, A enviar\u00e1 solicitudes a B, que luego reenviar\u00e1 la solicitud a C. C enviar\u00e1 una respuesta a B, que reenviar\u00e1 la respuesta a A.</p> <p>\u00bfPor qu\u00e9 agregar este intermediario adicional a nuestra actividad en Internet?</p> <p></p> <p>Hay algunas razones por las que uno podr\u00eda querer usar un proxy de reenv\u00edo:</p> <ul> <li> <p>Para evitar restricciones de navegaci\u00f3n estatales o institucionales: algunos gobiernos, escuelas y otras organizaciones usan firewalls para dar a sus usuarios acceso a una versi\u00f3n limitada de Internet. Se puede usar un proxy de reenv\u00edo para sortear estas restricciones, ya que permiten que el usuario se conecte al proxy en lugar de directamente a los sitios que est\u00e1 visitando.</p> </li> <li> <p>Para bloquear el acceso a cierto contenido: a la inversa, los proxies tambi\u00e9n se pueden configurar para bloquear el acceso de un grupo de usuarios a ciertos sitios. Por ejemplo, una red escolar puede estar configurada para conectarse a la web a trav\u00e9s de un proxy que habilita reglas de filtrado de contenido, neg\u00e1ndose a reenviar respuestas de Facebook y otros sitios de redes sociales.</p> </li> <li> <p>Para proteger su identidad en l\u00ednea: en algunos casos, los usuarios habituales de Internet simplemente desean un mayor anonimato en l\u00ednea, pero en otros casos, los usuarios de Internet viven en lugares donde el gobierno puede imponer graves consecuencias a los disidentes pol\u00edticos. Criticar al gobierno en un foro web o en las redes sociales puede dar lugar a multas o encarcelamiento para estos usuarios. Si uno de estos disidentes usa un proxy de reenv\u00edo para conectarse a un sitio web donde publica comentarios pol\u00edticamente sensibles, la direcci\u00f3n IP utilizada para publicar los comentarios ser\u00e1 m\u00e1s dif\u00edcil de rastrear hasta el disidente. Solo estar\u00e1 visible la direcci\u00f3n IP del servidor proxy.</p> </li> </ul>"},{"location":"practica3/#en-que-se-diferencia-un-proxy-inverso","title":"\u00bfEn qu\u00e9 se diferencia un proxy inverso?","text":"<p>Estar\u00edamos hablando del caso opuesto al anterior.</p> <p>Un proxy inverso es un servidor que se encuentra frente a uno o m\u00e1s servidores web, interceptando las solicitudes de los clientes. Esto es diferente de un proxy de reenv\u00edo, donde el proxy se encuentra frente a los clientes. Con un proxy inverso, cuando los clientes env\u00edan solicitudes al servidor de un sitio web, esas solicitudes son interceptadas en la frontera de la red por el servidor proxy inverso. El servidor proxy inverso enviar\u00e1 solicitudes y recibir\u00e1 respuestas del servidor del sitio web.</p> <p>La diferencia entre un proxy directo y inverso es sutil pero importante. Una forma simplificada de resumir ser\u00eda decir que un proxy de reenv\u00edo se encuentra frente a un cliente y garantiza que ning\u00fan servidor de origen se comunique nunca directamente con ese cliente espec\u00edfico. Por otro lado, un proxy inverso se encuentra frente a un servidor de origen y garantiza que ning\u00fan cliente se comunique nunca directamente con ese servidor de origen.</p> <p>Una vez m\u00e1s, ilustremos nombrando las m\u00e1quinas involucradas:</p> <ul> <li> <p>D: cualquier n\u00famero de ordenadores dom\u00e9sticos de los usuarios</p> </li> <li> <p>E: este es un servidor proxy inverso</p> </li> <li> <p>F: uno o m\u00e1s servidores de origen</p> </li> </ul> <p></p> <p>Normalmente, todas las solicitudes de D ir\u00edan directamente a F, y F enviar\u00eda respuestas directamente a D. Con un proxy inverso, todas las solicitudes de D ir\u00e1n directamente a E, y E enviar\u00e1 sus solicitudes ay recibir\u00e1 respuestas de F. E luego transmita las respuestas apropiadas a D.</p> <p>A continuaci\u00f3n se describen algunos de los beneficios de un proxy inverso:</p> <ul> <li> <p>Balanceo de carga: es posible que un sitio web popular que recibe millones de usuarios todos los d\u00edas no pueda manejar todo el tr\u00e1fico entrante del sitio con un solo servidor de origen. En cambio, el sitio se puede distribuir entre un grupo de servidores diferentes, todos manejando solicitudes para el mismo sitio. En este caso, un proxy inverso puede proporcionar una soluci\u00f3n de balanceo de carga que distribuir\u00e1 el tr\u00e1fico entrante de manera uniforme entre los diferentes servidores para evitar que un solo servidor se sobrecargue. En el caso de que un servidor falle por completo, otros servidores pueden intensificar para manejar el tr\u00e1fico.</p> </li> <li> <p>Protecci\u00f3n contra ataques: con un proxy inverso en su lugar, un sitio web o servicio nunca necesita revelar la direcci\u00f3n IP de su (s) servidor (es) de origen. Esto hace que sea mucho m\u00e1s dif\u00edcil para los atacantes aprovechar un ataque dirigido contra ellos, como un ataque DdoS.</p> </li> <li> <p>Almacenamiento en cach\u00e9: un proxy inverso tambi\u00e9n puede almacenar contenido en cach\u00e9 , lo que resulta en un rendimiento m\u00e1s r\u00e1pido. Por ejemplo, si un usuario en Par\u00eds visita un sitio web con proxy inverso con servidores web en Los \u00c1ngeles, el usuario podr\u00eda conectarse a un servidor proxy inverso local en Par\u00eds, que luego tendr\u00e1 que comunicarse con un servidor de origen en Los \u00c1ngeles. El servidor proxy luego puede almacenar en cach\u00e9 (o guardar temporalmente) los datos de respuesta. Los usuarios parisinos posteriores que naveguen por el sitio obtendr\u00e1n la versi\u00f3n en cach\u00e9 local del servidor proxy inverso parisino, lo que dar\u00e1 como resultado un rendimiento mucho m\u00e1s r\u00e1pido.</p> </li> <li> <p>Cifrado SSL - Cifrado y descifrado SSL (o TLS comunicaciones) para cada cliente pueden ser computacionalmente caro para un servidor de origen. Se puede configurar un proxy inverso para descifrar todas las solicitudes entrantes y cifrar todas las respuestas salientes, liberando valiosos recursos en el servidor de origen.</p> </li> </ul> <p></p>"},{"location":"practica3/#tarea","title":"Tarea","text":""},{"location":"practica3/#configuraciones","title":"Configuraciones","text":""},{"location":"practica3/#nginx-servidor-web","title":"Nginx servidor web","text":"<p>Vamos a configurar dos Debian con sendos servidores Nginx. Ten\u00e9is la m\u00e1quina virtual inicial y deb\u00e9is clonarla para tener una segunda:</p> <ul> <li> <p>Uno servir\u00e1 las p\u00e1ginas web que ya hemos configurado, as\u00ed pues utilizaremos el servidor que ya tenemos configurado de la Pr\u00e1ctica 2.1.</p> </li> <li> <p>El nuevo servidor clon Debian con Nginx configurado como proxy inverso</p> </li> <li> <p>Realizaremos las peticiones HTTP desde el navegador web de nuestra m\u00e1quina f\u00edsica/anfitri\u00f3n hacia el proxy clonado, que nos redirigir\u00e1 al servidor web original</p> </li> </ul> <p>[!WARNING]Cuidado</p> <p>Ojo al clonar las m\u00e1quinas virtuales porque hay que darle a crear una nueva MAC, de lo contrario no tendr\u00e9is IP en esa m\u00e1quina.</p> <p>El diagrama de red quedar\u00eda as\u00ed:</p> <p></p> <p></p> <p>Para que todo quede m\u00e1s diferenciado y os quede m\u00e1s claro que la petici\u00f3n est\u00e1 pasando por el proxy inverso y llega al servidor web destino, vamos a hacer que cada uno de los servidores escuche las peticiones en un puerto distinto.</p> <ol> <li> <p>En primer lugar, deb\u00e9is cambiar el nombre que tuviera vuestra web por el de <code>webserver</code>, ello implica:</p> </li> <li> <p>Cambiar el nombre del archivo de configuraci\u00f3n de sitios disponibles para Nginx</p> </li> <li> <p>Cambiar el nombre del sitio web dentro de este archivo de configuraci\u00f3n donde haga falta</p> </li> </ol> <p></p> <p></p> <ul> <li>No os olvid\u00e9is de eliminar el link simb\u00f3lico antiguo con el comando <code>unlink nombre_del_link</code> dentro de la carpeta <code>sites-enabled</code> y crear el nuevo para el nuevo nombre de archivo.</li> </ul> <p></p> <ol> <li>En el archivo de configuraci\u00f3n del sitio web, en lugar de hacer que el servidor escuche en el puerto 80, cambiadlo al 8080.</li> </ol> <p></p> <ol> <li>Reiniciar Nginx</li> </ol> <p></p>"},{"location":"practica3/#nginx-proxy-inverso","title":"Nginx proxy inverso","text":"<p>Ahora, cuando intentamos acceder a <code>http://ejemplo-proxy</code> (o el nombre que tuvier\u00e1is de vuestra web de las pr\u00e1cticas anteriores), en realidad estaremos accediendo al proxy, que nos redirigir\u00e1 a <code>http://webserver:8080</code>, el servidor web que acabamos de configurar para que escuche con ese nombre en el puerto 8080.</p> <p>Para ello:</p> <ul> <li> <p>Crear un archivo de configuraci\u00f3n en sites-available con el nombre <code>ejemplo-proxy</code> (o el que tuvier\u00e1is vosotros)</p> </li> <li> <p>Este archivo de configuraci\u00f3n ser\u00e1 m\u00e1s simple, tendr\u00e1 la siguiente forma</p> </li> </ul> <pre><code>server { \n    listen __; \n    server_name ____________; \n    location / { \n    proxy_pass http://_________:____; \n    } \n} \n</code></pre> <p>Donde, mirando el diagrama de red y teniendo en cuenta la configuraci\u00f3n hecha hasta ahora, deb\u00e9is completar:</p> <ul> <li> <p>El puerto donde est\u00e1 escuchando el proxy inverso</p> </li> <li> <p>El nombre de vuestro dominio o sitio web original al que accedemos en el proxy</p> </li> <li> <p>La directiva <code>proxy_pass</code> indica a d\u00f3nde se van a redirigir las peticiones, esto es, al servidor web. Por tanto, deb\u00e9is poner la IP y n\u00famero de puerto adecuados de vuestro sitio web configurado en el apartado anterior.</p> </li> <li> <p>Crear el link simb\u00f3lico pertinente</p> </li> </ul> <p></p> <p>Esto es para simular la situaci\u00f3n en la que nosotros, como clientes, cuando accedamos a nuestro sitio web, no necesitemos saber c\u00f3mo est\u00e1 todo configurado, s\u00f3lo necesitamos saber el nombre de la web.</p> <p>[!WARNING]\u00a1Atenci\u00f3n, muy importante!</p> <p>Deb\u00e9is modificar el archivo host que configurast\u00e9is en la pr\u00e1ctica 2.1. Si mir\u00e1is el diagrama de red, ahora el nombre de vuestro sitio web se corresponder\u00e1 con la IP de la nueva m\u00e1quina clon que hace de proxy. Ser\u00e1 \u00e9sta la encargada de redirigirnos autom\u00e1ticamente al verdadero sitio web.</p> <p></p>"},{"location":"practica3/#comprobaciones","title":"Comprobaciones","text":"<p>Si acced\u00e9is a vuestro sitio web, deb\u00e9is poder seguir accediendo sin problemas.</p> <ul> <li>Comprobad en los access.log de los dos servidores que llega la petici\u00f3n</li> </ul> <p></p> <p></p> <ul> <li>Comprobad adem\u00e1s la petici\u00f3n y respuesta con las herramientas de desarrollador de Firefox en Xubuntu. Pulsando F12 en el navegador os aparecer\u00e1n estas herramientas</li> </ul> <p>Comprobaci\u00f3n de ejemplo:</p> <p></p> <p>En la primera petici\u00f3n (marcada en rojo), utilizando el apartado \u201cRed\u201d (tambi\u00e9n marcado en rojo) y tambi\u00e9n en rojo est\u00e1 se\u00f1alado d\u00f3nde se puede ver la respuesta de la petici\u00f3n GET HTTP (200 OK).</p> <p>Tambi\u00e9n vemos las cabeceras que se incluyen en la petici\u00f3n (m\u00e9todo GET) y en la respuesta a esta petici\u00f3n.</p>"},{"location":"practica3/#anadiendo-cabeceras","title":"A\u00f1adiendo cabeceras","text":"<p>Adem\u00e1s de haber mirado los logs, vamos a demostrar a\u00fan de forma m\u00e1s clara que la petici\u00f3n est\u00e1 pasando por el proxy inverso y que est\u00e1 llegando al servidor web y que vuelve por el mismo camino.</p> <p>Si record\u00e1is de teor\u00eda, el servidor web es capaz de a\u00f1adir cabeceras en las respuestas a las peticiones.</p> <p>As\u00ed pues, vamos a configurar tanto el proxy inverso como el servidor web para que a\u00f1adan cada uno la cabecera \u201cHost\u201d que tambi\u00e9n vimos en teor\u00eda.</p> <p>Para a\u00f1adir cabeceras, en el archivo de configuraci\u00f3n del sitio web debemos a\u00f1adir dentro del bloque <code>location / { \u2026 }</code> debemos a\u00f1adir la directiva:</p> <pre><code>add_header Host nombre_del_host;\n</code></pre> <ol> <li>A\u00f1adiremos primero esta cabecera \u00fanicamente en el archivo de configuraci\u00f3n del sitio web del proxy inverso. El Nombre_del_host ser\u00e1 Proxy_inverso_vuestronombre.</li> </ol> <p></p> <ol> <li>Reiniciamos Nginx</li> </ol> <p></p> <ol> <li> <p>Comprobamos que podemos acceder al sitio web sin problemas</p> </li> <li> <p>Con las herramientas de desarrollador comprobamos que la petici\u00f3n ha pasado por el proxy inverso que ha a\u00f1adido la cabecera en la respuesta:</p> </li> </ol> <p></p> <p>En nuestro caso, aun habiendo hecho estos ajustes, sigue sin salir el host con el nombre que le hemos indicado.</p> <p></p> <p></p> <p>Para cambiar esto lo que hemos hecho ha sido a\u00f1adir dos cambio de nombre en el servidor proxy.</p> <p>Hacemos lo propio con el servidor web. Esta vez el <code>Nombre_del_host</code> ser\u00e1 <code>servidor_web_vuestronombre</code>.</p> <p></p> <p>Si todo est\u00e1 configurado correctamente, al examinar las peticiones y respuestas, os aparecer\u00e1n las dos cabeceras que han incluido en la respuesta tanto el proxy inverso como el servidor web. .</p> <p></p> <p>Es muy importante que para realizar estas comprobaciones teng\u00e1is marcado el checkbox Desactivar cach\u00e9 o en una ventana privada del navegador.</p> <p></p> <p>Si no marc\u00e1is esto, la p\u00e1gina se guardar\u00e1 en la memoria cach\u00e9 del navegador y no estar\u00e9is recibiendo la respuesta del servidor sino de la cach\u00e9 del navegador, lo que puede dar lugar a resultados err\u00f3neos.</p>"},{"location":"practica4/","title":"Pr\u00e1ctica 2.4 - Balanceo de carga con proxy inverso en Nginx","text":"<p>[!WARNING]Atenci\u00f3n</p> <p>Estos apuntes siguen aqu\u00ed para temas de consulta pero a d\u00eda de hoy tiene ciertas partes que pueden haberse quedado obsoletas (Heroku por ejemplo ahora es de pago), los ir\u00e9 actualizando en la medida que el tiempo me lo permita en esta nueva p\u00e1gina.</p>"},{"location":"practica4/#requisitos-aantes-de-comenzar-la-practica","title":"Requisitos aantes de comenzar la pr\u00e1ctica","text":"<p>[!WARNING]Atenci\u00f3n, muy importante antes de empezar</p> <ul> <li>La pr\u00e1ctica 2.3 debe estar funcionando correctamente</li> <li>No empezar la pr\u00e1ctica antes de tener la 2.3 funcionando y comprobada</li> </ul>"},{"location":"practica4/#introduccion","title":"Introducci\u00f3n","text":"<p>Los servidores proxy inversos y los balanceadores de carga son componentes de una arquitectura inform\u00e1tica cliente-servidor. Ambos act\u00faan como intermediarios en la comunicaci\u00f3n entre los clientes y los servidores, realizando funciones que mejoran la eficiencia.</p> <p>Las definiciones b\u00e1sicas son simples:</p> <ul> <li> <p>Un proxy inverso acepta una solicitud de un cliente, la reenv\u00eda a un servidor que puede cumplirla y devuelve la respuesta del servidor al cliente.</p> </li> <li> <p>Un balanceador de carga distribuye las solicitudes entrantes del cliente entre un grupo de servidores, en cada caso devolviendo la respuesta del servidor seleccionado al cliente apropiado.</p> </li> </ul> <p>Suenan bastante similares, \u00bfverdad? Ambos tipos de aplicaciones se ubican entre clientes y servidores, aceptando solicitudes del primero y entregando respuestas del segundo. No es de extra\u00f1ar que haya confusi\u00f3n sobre qu\u00e9 es un proxy inverso y un balanceador de carga. Para ayudar a diferenciarlos, exploremos cu\u00e1ndo y por qu\u00e9 normalmente se implementan en un sitio web. .</p>"},{"location":"practica4/#proxy-inverso","title":"Proxy inverso","text":"<p>Ya conocemos este concepto de la pr\u00e1ctica anterior.</p> <p>Mientras que implementar un balanceador de carga solo tiene sentido cuando se tienen varios servidores, a menudo tiene sentido implementar un proxy inverso incluso con un solo servidor web o servidor de aplicaciones.</p> <p>Se puede pensar en el proxy inverso como la \"cara p\u00fablica\" de un sitio web. Su direcci\u00f3n es la que se anuncia para el sitio web y se encuentra en la frontera de la red del sitio para aceptar solicitudes de navegadores web y aplicaciones m\u00f3viles para el contenido alojado en el sitio web.</p>"},{"location":"practica4/#balanceadores-de-carga","title":"Balanceadores de carga","text":"<p>Los balanceadores de carga se implementan con mayor frecuencia cuando un sitio necesita varios servidores porque el volumen de solicitudes es demasiado para que un solo servidor lo maneje de manera eficiente.</p> <p>La implementaci\u00f3n de varios servidores tambi\u00e9n elimina un solo punto de fallo, lo que hace que el sitio web sea m\u00e1s confiable. Por lo general, todos los servidores alojan el mismo contenido, y el trabajo del balanceador de carga es distribuir la carga de trabajo de manera que se haga el mejor uso de la capacidad de cada servidor, evite la sobrecarga en cualquiera de ellos y d\u00e9 como resultado la respuesta m\u00e1s r\u00e1pida posible al cliente. .</p> <p>Un balanceador de carga tambi\u00e9n puede mejorar la experiencia del usuario al reducir la cantidad de respuestas de error que ve el cliente. Lo hace detectando cu\u00e1ndo los servidores caen y desviando las solicitudes de ellos a los otros servidores del grupo. En la implementaci\u00f3n m\u00e1s simple, el balanceador de carga detecta el estado del servidor al interceptar las respuestas de error a las solicitudes regulares.</p> <p>En esta pr\u00e1ctica tendremos el escenario donde Nginx har\u00e1 tanto de proxy inverso como de balanceador de carga al mismo tiempo.</p> <p>[!NOTE] Info</p> <p>En esta pr\u00e1ctica tendremos un escenario donde Nginx har\u00e1 tanto de proxy inverso como de balanceador de carga al mismo tiempo</p>"},{"location":"practica4/#tarea","title":"Tarea","text":"<p>Vamos a configurar dos servidores web Nginx con dos m\u00e1quinas Debian, adem\u00e1s de reutilizar el proxy inverso Nginx configurado en la pr\u00e1ctica anterior. Partiremos por tanto de la configuraci\u00f3n de la pr\u00e1ctica anterior, a\u00f1adiendo lo necesario:</p> <ul> <li>Cada servidor web presentar\u00e1 un sitio web espec\u00edfico para esta pr\u00e1ctica<ul> <li>El webserver2 debe tener la IP asignada de forma fija mediante la configuraci\u00f3n DHCP.</li> </ul> </li> <li>El proxy inverso que ya ten\u00edamos configurado, habr\u00e1 ahora que configurarlo para que realice el balanceo de carga que deseamos</li> <li>Realizaremos las peticiones HTTP desde el navegador web de nuestra m\u00e1quina anfitriona.</li> </ul> <p>El diagrama de red quedar\u00eda as\u00ed:</p> <p></p> <p>Haremos las peticiones web desde el navegador al proxy inverso, que las repartir\u00e1 entre los dos servidores web que tenemos.</p> <p>Accederemos a <code>http://balanceo</code> y debemos observar que las peticiones, efectivamente, se van repartiendo entre el servidor 1 y el 2.</p>"},{"location":"practica4/#configuraciones","title":"Configuraciones","text":"<p>[!WARNING] Atenci\u00f3n</p> <p>Ya no vamos a utilizar los sitios web que hemos configurado en las pr\u00e1cticas anteriores. Por ello, para evitarnos una serie de problemas que pueden surgir, vamos a desactivarlos.</p> <p>Dentro de la carpeta <code>/etc/nginx/sites-enabled</code> debemos ejecutar <code>unlink nombre_archivo</code> para cada uno de los archivos de los sitios web que tenemos.</p> <p>Si no hac\u00e9is esto obtendr\u00e9is errores en todas las pr\u00e1cticas que quedan de este tema.</p>"},{"location":"practica4/#nginx-servidor-web-1","title":"Nginx Servidor Web 1","text":"<p>El primer servidor web ser\u00e1 el servidor principal que hemos venido utilizando hasta ahora durante el curso, el original, donde tenemos instalado ya el servicio Web.</p> <p>Debemos configurar este servidor web para que sirva el siguiente <code>index.html</code> que deb\u00e9is crear dentro de la carpeta <code>/var/www/webserver1/html</code>:</p> <pre><code>&lt;html lang=\"es\"&gt;\n&lt;head&gt;\n    &lt;title&gt;Prueba de balanceo de carga con Nginx&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h2&gt;Este es el servidor web 1&lt;/h2&gt;\n    &lt;p&gt;Comprueba el balanceo de carga con Nginx recargando esta p\u00e1gina&lt;/p&gt;&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <ul> <li>El nombre del sitio web que deb\u00e9is utilizar en los archivos correspondientes (sites-available\u2026) que deb\u00e9is crear para Nginx es <code>webserver1</code>, as\u00ed como en sus configuraciones. Fij\u00e1os en las configuraciones que hicisteis en pr\u00e1cticas anteriores a modo de referencia.</li> <li>El sitio web debe escuchar en el puerto 8080.</li> <li>Deb\u00e9is a\u00f1adir una cabecera que se llame <code>Serv_Web1_vuestronombre</code>.</li> </ul>"},{"location":"practica4/#nginx-servidor-web-2","title":"Nginx Servidor Web 2","text":"<p>Debe ser una m\u00e1quina Debian, clon del servidor web 1.</p> <p>En este servidor web debemos realizar una configuraci\u00f3n id\u00e9ntica al servidor web 1 pero cambiando <code>webserver1</code> por <code>webserver2</code> (tambi\u00e9n en el index.html), as\u00ed como el nombre de la cabecera a\u00f1adida, que ser\u00e1 <code>Serv_Web2_vuestronombre</code>.</p> <p>[!WARNING]Warning</p> <p>Es importante que no quede ninguna referencia a webserver1 por ning\u00fan archivo, de otra forma os dar\u00e1 resultados err\u00f3neos y os dificultar\u00e1 mucho encontrar el error.</p>"},{"location":"practica4/#nginx-proxy-inverso","title":"Nginx Proxy Inverso","text":"<p>Ya disponemos de los dos servidores web entre los que se van a repartir las peticiones que realice el cliente desde el navegador.</p> <p>Vamos, por tanto, a configurar el proxy inverso para que realice este reparto de peticiones:</p> <p>En sites-available deb\u00e9is crear el archivo de configuraci\u00f3n con el nombre balanceo.</p> <p>Este archivo tendr\u00e1 el siguiente formato:</p> <pre><code>    upstream backend_hosts {\n                random;\n                server ________:____;\n                server ________:____;\n    }\n            server {\n                listen 80;\n                server_name ________;      \n                location / {\n                    proxy_pass http://backend_hosts;\n                }\n            }\n</code></pre> <p>Donde:</p> <ul> <li> <p>El bloque upstream \u2192 son los servidores entre los que se va a repartir la carga, que son los dos que hemos configurado anteriormente.</p> </li> <li> <p>Si mir\u00e1is el diagrama y ten\u00e9is en cuenta la configuraci\u00f3n que hab\u00e9is hecho hasta ahora, aqu\u00ed deber\u00e9is colocar la IP de cada servidor, as\u00ed como el puerto donde est\u00e1 escuchando las peticiones web.</p> </li> <li> <p>A este grupo de servidores le ponemos un nombre, que es <code>backend_hosts</code></p> </li> </ul> <p>[!NOTE]Aclaraci\u00f3n</p> <p>En un sitio web, el backend se encarga de todos los procesos necesarios para que la web funcione de forma correcta. Estos procesos o funciones no son visibles pero tienen mucha importancia en el buen funcionamiento de un sitio web.</p> <ul> <li> <p>El par\u00e1metro random lo que hace es repartir las peticiones HTTP que llegan al proxy inverso de forma completamente aleatoria entre el grupo de servidores que se haya definido en el bloque upstream (en nuestro caso s\u00f3lo hay dos).</p> <ul> <li>Pondremos random porque es lo m\u00e1s f\u00e1cil para comprobar que todo funciona bien en la pr\u00e1ctica, pero hay diferentes formas de repartir la carga (las peticiones HTTP).</li> </ul> </li> </ul>"},{"location":"practica4/#comprobaciones","title":"Comprobaciones","text":"<p>Si acced\u00e9is a vuestro sitio web, deb\u00e9is poder seguir accediendo sin problemas.</p> <ul> <li> <p>Comprobad d\u00e1ndole repetidamente a F5, que acced\u00e9is cada vez a uno de los servidores. Se os mostrar\u00e1 el contenido del index.html del servidor correspondiente cada vez.</p> <ul> <li>Para una doble comprobaci\u00f3n, utilizando las herramientas de desarrollador, mostrad que la web que se os muestra coincide con la cabecera que ha a\u00f1adido el servidor web en la respuesta HTTP.</li> </ul> </li> </ul> <p>[!NOTE]Recordatorio</p> <p>Recordad que es muy importante que para realizar estas comprobaciones teng\u00e1is marcado el checkbox Desactivar cach\u00e9.</p> <p></p> <p>Si no marc\u00e1is esto, la p\u00e1gina se guardar\u00e1 en la memoria cach\u00e9 del navegador y no estar\u00e9is recibiendo la respuesta del servidor sino de la cach\u00e9 del navegador, lo que puede dar lugar a resultados err\u00f3neos.</p> <p>Otra opci\u00f3n, si esto no funcionara, es hacer las pruebas con una nueva ventana privada del navegador.</p>"},{"location":"practica4/#comprobacion-del-balanceo-de-carga-cuando-cae-un-servidor","title":"Comprobaci\u00f3n del balanceo de carga cuando cae un servidor","text":"<p>Nuestro balanceador de carga est\u00e1 constantemente monitorizando \u201cla salud\u201d de los servidores web. De esta forma, si uno deja de funcionar por cualquier raz\u00f3n, siempre enviar\u00e1 las solicitudes a los que queden \u201cvivos\u201d. Vamos a comprobarlo:</p> <ul> <li> <p>Para el servicio Nginx en el servidor web 1 y comprueba, de la misma forma que en el apartado anterior, que todas las solicitudes se env\u00edan ahora al servidor web 2</p> </li> <li> <p>Tras iniciar de nuevo Nginx en el servidor web 1, repite el proceso con el servidor web 2.</p> </li> </ul>"},{"location":"practica4/#cuestiones-finales","title":"Cuestiones finales","text":"<p>[!TIP]Cuesti\u00f3n 1</p> <p>Busca informaci\u00f3n de qu\u00e9 otros m\u00e9todos de balanceo se pueden aplicar con Nginx y describe al menos 3 de ellos.</p> <p>Otros m\u00e9todos de balanceo que se pueden aplicar con Nginx son por ejemplo:</p> <ol> <li>Round-robin \u2192 Lo que hace es distribuir las solicitudes de forma secuencial entre los servidores.</li> <li>Least Connections \u2192 Env\u00eda las solicitudes al servidor que contiene menos conexiones activas.</li> <li>IP Hash \u2192 La distribuci\u00f3n se basa en la direcci\u00f3n IP del cliente. Le asigna al mismo cliente el mismo servidor siempre.</li> </ol> <p>[!TIP]Cuesti\u00f3n 2</p> <p>Si quiero a\u00f1adir 2 servidores web m\u00e1s al balanceo de carga, describe detalladamente qu\u00e9 configuraci\u00f3n habr\u00eda que a\u00f1adir y d\u00f3nde.</p> <p>Solamente hay que a\u00f1adir las ip al bloque upstream de balanceo. Por ejemplo:</p> <pre><code>upstream backend_hosts {\n    random;\n    server 192.168.159.154:8080;\n    server 192.168.159.144:8080;\n    server 192.168.159.168:8080;\n    server 192.168.159.129:8080;\n}\n</code></pre> <p>[!TIP]Cuesti\u00f3n 3</p> <p>Describe todos los pasos que deber\u00edamos seguir y configurar para realizar el balanceo de carga con una de las webs de pr\u00e1cticas anteriores.</p> <p>Indicad la configuraci\u00f3n de todas las m\u00e1quinas (webservers, proxy...) y de sus servicios</p> <p>Para realizar el balanceo de carga utilizando Nginx con los servidores web de las pr\u00e1cticas anteriores, necesitas seguir una serie de pasos que abarcan la configuraci\u00f3n de los servidores web, el proxy inverso y las pruebas de funcionamiento. A continuaci\u00f3n, se describe un procedimiento detallado que incluye la configuraci\u00f3n de todas las m\u00e1quinas involucradas.</p>"},{"location":"practica4/#paso-1-configuracion-de-los-servidores-web","title":"PASO 1: CONFIGURACI\u00d3N DE LOS SERVIDORES WEB","text":""},{"location":"practica4/#webserver1","title":"WEBSERVER1","text":""},{"location":"practica4/#desactivamos-los-sitios-web-de-las-practicas-anteriores","title":"Desactivamos los sitios web de las practicas anteriores","text":"<p>Para ello utilizamos el comando sudo unlink <code>/etc/nginx/sites-enabled/webserver</code></p> <p></p>"},{"location":"practica4/#creamos-el-archivo-de-configuracion-para-webserver1-en-la-carpeta-etcnginxsites-available-y-enlazamos-a-sites-enabled","title":"Creamos el archivo de configuracion para webserver1 en la carpeta /etc/nginx/sites-available y enlazamos a sites-enabled","text":"<pre><code>server {\n    listen 8080;\n    server_name webserver1;\n\n    root /var/www/webserver1/html;\n    index index.html;\n\n    add_header Serv_Web1 \"tu_nombre\";\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre> <p>Despu\u00e9s de poner esto en el archivo <code>/etc/nginx/sites-available/webserver1</code> enlazamos a <code>sites-enables</code> con el comando sudo ln -s /etc/nginx/sites-available/webserver1 /etc/nginx/sites-enabled/</p> <p></p>"},{"location":"practica4/#archivo-indexhtml-en-varwwwwebserver1html","title":"Archivo index.html en /var/www/webserver1/html","text":"<p>Creamos el directorio <code>/var/www/webserver1/html</code> y creamos en \u00e9l, el archivo <code>index.html</code> con el siguiente c\u00f3digo:</p> <pre><code>&lt;html lang=\"es\"&gt;\n&lt;head&gt;\n    &lt;title&gt;Prueba de balanceo de carga con Nginx&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h2&gt;Este es el servidor web 1&lt;/h2&gt;\n    &lt;p&gt;Comprueba el balanceo de carga con Nginx recargando esta p\u00e1gina&lt;/p&gt;&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p></p>"},{"location":"practica4/#reiniciar-nginx-con-el-comando-sudo-systemctl-restart-nginxconfig","title":"Reiniciar NGINX con el comando: <code>sudo systemctl restart nginx.config</code>","text":""},{"location":"practica4/#clonamos-ahora-la-maquina-virtual-y-le-ponemos-el-nombre-webserver2","title":"Clonamos ahora la m\u00e1quina virtual y le ponemos el nombre webserver2","text":""},{"location":"practica4/#importante","title":"IMPORTANTE","text":"<p>Hay que cambiar la opci\u00f3n de la direcci\u00f3n MAC</p> <p></p> <p></p>"},{"location":"practica4/#webserver2","title":"WEBSERVER2","text":""},{"location":"practica4/#repetimos-los-procesos-pero-cambiando-webserver1-por-webserver2","title":"Repetimos los procesos pero cambiando webserver1 por webserver2","text":""},{"location":"practica4/#cambios-en-etcnginxsites-availablewebserver2","title":"Cambios en /etc/nginx/sites-available/webserver2","text":""},{"location":"practica4/#cambios-html","title":"Cambios html","text":""},{"location":"practica4/#reiniciar-nginx","title":"Reiniciar NGINX","text":""},{"location":"practica4/#paso-2-configuracion-del-proxy-inverso","title":"PASO 2: CONFIGURACI\u00d3N DEL PROXY INVERSO","text":""},{"location":"practica4/#vamos-a-la-maquina-que-configuramos-el-proxy-inverso-en-la-practica-23","title":"Vamos a la m\u00e1quina que configuramos el proxy inverso en la pr\u00e1ctica 2.3","text":""},{"location":"practica4/#balanceo-de-carga","title":"Balanceo de Carga","text":""},{"location":"practica4/#archivo-de-configuracion","title":"Archivo de configuraci\u00f3n","text":""},{"location":"practica4/#enlace-de-balanceo-a-sites-enabled","title":"Enlace de balanceo a sites-enabled","text":""},{"location":"practica4/#reiniciar-nginx_1","title":"Reiniciar NGINX","text":""},{"location":"practica4/#paso-3-configuracion-de-etchosts","title":"PASO 3: CONFIGURACI\u00d3N DE /ETC/HOSTS","text":""},{"location":"practica4/#webserver1_1","title":"Webserver1","text":""},{"location":"practica4/#webserver2_1","title":"Webserver2","text":""},{"location":"practica4/#proxy-inverso_1","title":"Proxy inverso","text":""},{"location":"practica4/#reiniciar-nginx_2","title":"Reiniciar NGINX","text":""},{"location":"practica4/#paso-4-comprobaciones","title":"PASO 4: COMPROBACIONES","text":""},{"location":"practica4/#mensajes-que-se-muestran-al-entrar-a-httpbalanceo-y-pulsar-f5-desde-la-maquina-anfitriona","title":"Mensajes que se muestran al entrar a http://balanceo y pulsar F5 desde la m\u00e1quina anfitriona.","text":""},{"location":"practica5/","title":"Pr\u00e1ctica 2.5 - Proxy inverso y balanceo de carga con SSL en NGINX","text":"<p>[!WARNING]Atenci\u00f3n</p> <p>Estos apuntes siguen aqu\u00ed para temas de consulta pero a d\u00eda de hoy tiene ciertas partes que pueden haberse quedado obsoletas (Heroku por ejemplo ahora es de pago), los ir\u00e9 actualizando en la medida que el tiempo me lo permita en esta nueva p\u00e1gina.</p>"},{"location":"practica5/#requisitos-antes-de-comenzar-la-practica","title":"Requisitos antes de comenzar la pr\u00e1ctica","text":"<p>[!WARNING]Atenci\u00f3n, muy importante antes de comenzar</p> <p>La pr\u00e1ctica 4.4 ha d'estar funcionant correctament No comenzar la pr\u00e1ctica antes de tener la 1.3 funcionant i comprovada</p>"},{"location":"practica5/#introduccion","title":"Introducci\u00f3n","text":"<p>A partir de las pr\u00e1cticas anteriores hemos llegado a un escenario donde un proxy inverso act\u00faa de intermediario entre dos servidores web Nginx, balanceando la carga entre ellos.</p> <p>Ya dijimos que una importante funci\u00f3n que pod\u00eda tener un proxy inverso era realizar el cifrado y descifrado de SSL para utilizar HTTPS en los servidores web. De esta forma se aliviaba la carga de trabajo de los servidores web, ya que es una tarea que consume recursos.</p> <p>En definitiva, tendr\u00edamos un esquema como este:</p> <p></p> <p>Podr\u00eda llegarse a pensar que en t\u00e9rminos de seguridad no es adecuado que el tr\u00e1fico de red entre el balanceador de carga y los servidores web vaya sin cifrar (HTTP). Sin embargo, pensando en un caso real, la red privada y el proxy inverso/balanceador de carga, adem\u00e1s de estar en la misma red privada, suelen estar administrados por las mismas personas de la misma empresa, por lo que no supone un peligro real que ese tr\u00e1fico vaya sin cifrar.</p> <p>Podr\u00eda cifrarse si fuera necesario, pero entonces pierde sentido que el proxy inverso se encargue del cifrado SSL para HTTPS, ya que har\u00edamos el mismo trabajo dos veces.</p> <p>As\u00ed las cosas, nos quedaremos con el esquema de la imagen de m\u00e1s arriba para la pr\u00e1ctica.</p>"},{"location":"practica5/#certificados","title":"Certificados","text":"<p>HTTPS se basa en el uso de certificados digitales.</p> <p>Grosso modo, cuando entramos en una web v\u00eda HTTPS, \u00e9sta nos presenta un certificado digital para asegurar que es qui\u00e9n dice ser. \u00bfC\u00f3mo sabemos que ese certificado es v\u00e1lido? Debemos consultar a la Autoridad de Certificaci\u00f3n (CA) que emiti\u00f3 ese certificado si es v\u00e1lido.</p> <p>Las CA son entidades que emiten certificados y su funcionamiento se basa en la confianza. Confiamos en que los certificados emitidos y firmados por esas entidades son reales y funcionales.</p> <p></p> <p>Los navegadores web tienen precargadas las Autoridades de Certificaci\u00f3n en las que conf\u00edan por defecto a la hora de navegar por webs HTTPS:</p> <p></p> <p>Si accedemos a una web cuyo certificado no haya sido emitido y firmado por una de estas entidades, nos saltar\u00e1 el famoso aviso:</p> <p></p> <p>Ya que si el certificado no ha sido emitido y firmado por una CA de confianza, puede que se trate de una web maliciosa que nos suponga un riesgo de seguridad, como bien dice el aviso.</p>"},{"location":"practica5/#tarea","title":"Tarea","text":"<p>Partimos de la configuraci\u00f3n exacta de la pr\u00e1ctica anterior, que recordemos era esta:</p> <p></p> <p>Por lo que en esta pr\u00e1ctica simplemente debemos a\u00f1adir la configuraci\u00f3n SSL para el cifrado en el Proxy Inverso:</p> <p></p> <p>Tal y como quedar\u00e1 la configuraci\u00f3n, desde el cliente a\u00fan podr\u00edamos acceder a los dos servidores web con HTTP (pod\u00e9is probarlo) pero es algo que solucionaremos en siguientes temas, configurando un firewall para que s\u00f3lo la IP del proxy inverso pueda acceder por HTTP a los servidores web y nadie m\u00e1s.</p>"},{"location":"practica5/#creacion-de-certificado-autofirmado","title":"Creaci\u00f3n de certificado autofirmado","text":"<p>Nosotros no utilizaremos certificados de ninguna CA de confianza, b\u00e1sicamente porque:</p> <ul> <li>Nuestros servicios no est\u00e1n publicados en Internet</li> <li>Estos certificados son de pago</li> </ul> <p>As\u00ed pues, nosotros crearemos nuestros propios certificados y los firmaremos nosotros mismos como si fu\u00e9ramos una CA aut\u00e9ntica para poder simular este escenario.</p> <p>[!WARNING]Warning</p> <p>Esto provocar\u00e1 que cuando accedamos por HTTPS a nuestro sitio web por primera vez, nos salt\u00e9 el aviso de seguridad que se comentaba en la introducci\u00f3n.</p> <p>En este caso no habr\u00e1 peligro puesto que estamos 100% seguros que ese certificado lo hemos emitido nosotros para esta pr\u00e1ctica, no hay dudas.</p> <p>Veamos pues el proceso para generar los certificados y las claves asociadas a ellos (privada/p\u00fablica). En primer lugar debemos crear el siguiente directorio:</p> <p><code>/etc/nginx/ssl</code></p> <p>Podemos crear el certificado y las claves de forma simult\u00e1nea con un \u00fanico comando, donde:</p> <ul> <li><code>openssl</code>: esta es la herramienta por l\u00ednea de comandos b\u00e1sica para crear y administrar certificados, claves y otros archivos OpenSSL.</li> <li><code>req</code>: este subcomando se utiliza para generar una solicitud de certificados y tambi\u00e9n solicitudes de firma de certificados (CSR).</li> <li><code>-x509</code>: Esto modifica a\u00fan m\u00e1s el subcomando anterior al decirle a la herramienta que queremos crear un certificado autofirmado en lugar de generar una solicitud de firma de certificado, como suceder\u00eda normalmente.</li> <li><code>-nodes</code>: Esto le dice a OpenSSL que omita la opci\u00f3n de asegurar nuestro certificado con contrase\u00f1a. Necesitamos que Nginx pueda leer el archivo sin la intervenci\u00f3n del usuario cuando se inicia el servidor. Una contrase\u00f1a evitar\u00eda que esto sucediera ya que tendr\u00edamos que introducirla a mano despu\u00e9s de cada reinicio.</li> <li><code>-days 365</code>: esta opci\u00f3n establece el tiempo durante el cual el certificado se considerar\u00e1 v\u00e1lido. Lo configuramos para un a\u00f1o.</li> <li><code>-newkey rsa: 2048</code> : Esto especifica que queremos generar un nuevo certificado y una nueva clave al mismo tiempo. No creamos la clave necesaria para firmar el certificado en un paso anterior, por lo que debemos crearla junto con el certificado. La rsa:2048parte le dice que cree una clave RSA de 2048 bits de longitud.</li> <li><code>-keyout</code>: este par\u00e1metro le dice a OpenSSL d\u00f3nde colocar el archivo de clave privada generado que estamos creando.</li> <li><code>-out</code>: Esto le dice a OpenSSL d\u00f3nde colocar el certificado que estamos creando.</li> </ul> <p>El comando completo ser\u00eda as\u00ed:</p> <p></p> <p>Os solicitar\u00e1 que introduzc\u00e1is una serie de par\u00e1metros, como v\u00e9is en el recuadro rojo de abajo de la imagen. Deb\u00e9is introducir los mismos par\u00e1metros que en la imagen excepto en el \u201cOrganizational Unit Name\u201d que v\u00e9is recuadrado en amarillo. Ah\u00ed deber\u00e9is poner 2DAW \u2013 DEAW - Vuestronombre</p>"},{"location":"practica5/#configuracion-ssl-en-el-proxy-inverso","title":"Configuraci\u00f3n SSL en el proxy inverso","text":"<p>De la pr\u00e1ctica anterior, dentro del directorio <code>/etc/nginx/sites-available</code> ya deb\u00e9is tener el archivo de configuraci\u00f3n llamado \u201cbalanceo\u201d. Es precisamente aqu\u00ed donde realizaremos la configuraci\u00f3n para que el acceso al sitio web se realice mediante SSL (HTTPS).</p> <p>Dentro del bloque <code>server {\u2026}</code> deb\u00e9is cambiar el puerto de escucha (<code>listen 80</code>) por lo que v\u00e9is en la imagen de abajo, a\u00f1adiendo las siguientes l\u00edneas de configuraci\u00f3n tambi\u00e9n, de tal forma que quede:</p> <p></p> <p>Donde le est\u00e1is diciendo que:</p> <ul> <li>Escuche en el puerto 443 \u2192 Puerto por defecto de HTTPS</li> <li>El directorio donde est\u00e1 el certificado que hab\u00e9is generado anteriormente</li> <li>El directorio donde est\u00e1 la clave que hab\u00e9is generado anteriormente</li> <li>Los protocolos y tipos de cifrados que se pueden utilizar \u2192 Estas son las versiones de protocolos y los tipos de cifrados considerados seguros a d\u00eda de hoy (hay muchos m\u00e1s pero no se consideran seguros actualmente)</li> <li><code>server_name</code> ya lo ten\u00edais de la pr\u00e1ctica anterior, no hace falta tocarlo</li> <li>El archivo donde se guardan los logs cambia de nombre, ahora ser\u00e1 https_access.log</li> </ul> <p>Recordad que tras modificar cualquier configuraci\u00f3n de un servicio, hay que reiniciar el servicio, en este caso Nginx.</p>"},{"location":"practica5/#comprobaciones","title":"Comprobaciones","text":"<ul> <li>Si acced\u00e9is ahora a https://balanceo os deber\u00eda saltar un aviso de seguridad debido a que nuestro certificado es autofirmado, como coment\u00e1bamos anteriormente.</li> <li>Si a\u00f1ad\u00eds una una excepci\u00f3n podr\u00e9is acceder al sitio web y recargando repetidamente la p\u00e1gina con F5, ver\u00e9is que el balanceo de carga se hace correctamente accediendo mediante HTTPS.</li> <li>Para comprobar que los datos del certificado son, efectivamente, los vuestros pod\u00e9is comprobarlo as\u00ed. Pulsando en el candado de la barra de b\u00fasqueda:</li> </ul> <p>Con m\u00e1s informaci\u00f3n:</p> <p></p> <p>[!TIP]Info</p> <p>Aqu\u00ed tambi\u00e9n podr\u00e9is eliminar la excepci\u00f3n que hab\u00e9is a\u00f1adido en la p\u00e1gina de la advertencia de seguridad, por si necesit\u00e1is reiniciar las pruebas.</p> <p>Y por \u00faltimo, ver certificado:</p> <p></p> <p>Y podremos ver los detalles:</p> <p></p> <p>Si ahora intent\u00e1is acceder a <code>http://balanceo</code>, \u00bfdeber\u00edais poder acceder? Comprobadlo y describid qu\u00e9 pasa y por qu\u00e9.</p>"},{"location":"practica5/#redireccion-forzosa-a-https","title":"Redirecci\u00f3n forzosa a HTTPS","text":"<p>Para que, indistintamente de la forma por la que accedamos al sitio web balanceo, siempre se fuerce a utilizar HTTPS, necesitaremos una configuraci\u00f3n adicional.</p> <p>Necesitamos a\u00f1adir un bloque \u201cserver\u201d adicional y separado del otro, al archivo de configuraci\u00f3n de \u201cbalanceo\u201d. Algo as\u00ed:</p> <p></p> <p>Con esta configuraci\u00f3n le estamos diciendo que:</p> <ul> <li>Escuche en el puerto 80 (HTTP)</li> <li>Que el nombre al que responder\u00e1 el servidor/sitio web es balanceo</li> <li>Que guarde los logs de este bloque en ese directorio y con ese nombre</li> <li>Cuando se recibe una petici\u00f3n con las dos condiciones anteriores, se devuelve un c\u00f3digo HTTP 301:</li> <li>HTTP 301 Moved Permanently (Movido permanentemente en espa\u00f1ol) es un c\u00f3digo de estado de HTTP que indica que el host ha sido capaz de comunicarse con el servidor pero que el recurso solicitado ha sido movido a otra direcci\u00f3n permanentementeEs muy importante configurar las redirecciones 301 en los sitios web y para ello hay diferentes m\u00e9todos y sintaxis para realizar la redirecci\u00f3n 301.</li> <li>La redirecci\u00f3n 301 es un c\u00f3digo o comando insertado por un Webmaster que permite redirigir a los usuarios y buscadores de un sitio web de un sitio a otro.</li> </ul> <p>[!TIP]Aclaraci\u00f3n</p> <p>Es decir, lo que estamos haciendo es que cuando se reciba una petici\u00f3n HTTP (puerto 80) en <code>http://balanceo</code>, se redirija a <code>https://balanceo</code> (HTTPS)</p> <p>[!TIP]Tarea</p> <ul> <li>Eliminad del otro bloque <code>server{\u2026}</code> la l\u00edneas que hagan referencia a escuchar en el puerto 80 (listen 80\u2026).</li> <li>Reiniciad el servicio</li> <li>Comprobad ahora que cuando entr\u00e1is en <code>http://balanceo</code>, autom\u00e1ticamente os redirige a la versi\u00f3n segura de la web.</li> <li>Comprobad que cuando realiz\u00e1is una petici\u00f3n en el archivo de log <code>http_access.log</code> aparece la redirecci\u00f3n 301 y que, de la misma manera, aparece una petici\u00f3n GET en <code>https_access.log</code>.</li> </ul>"},{"location":"practica5/#eliminar-lineas-que-hagan-referencia-al-puerto","title":"Eliminar l\u00edneas que hagan referencia al puerto","text":""},{"location":"practica5/#reiniciar-el-servicio","title":"Reiniciar el servicio","text":""},{"location":"practica5/#cambio-de-httpbalanceo-a-httpsbalanceo","title":"Cambio de http://balanceo a https://balanceo","text":""},{"location":"practica5/#con-el-comando-http_accesslog-vemos-que-se-haya-hecho-la-comprobacion","title":"Con el comando http_access.log vemos que se haya hecho la comprobaci\u00f3n","text":""},{"location":"practica5/#y-lo-mismo-para-el-https_accesslog","title":"Y lo mismo para el https_access.log","text":""},{"location":"practica5/#cuestiones-finales","title":"Cuestiones finales","text":"<p>[!TIP]Cuesti\u00f3n 1</p> <p>Hemos configurado nuestro proxy inverso con todo lo que nos hace falta pero no nos funciona y da un error del tipo <code>This site can't provide a secure connection, ERR_SSL_PROTOCOL_ERROR</code>.</p> <p>Dentro de nuestro server block tenemos esto:</p> <p>```code server {     listen 443;     ssl_certificate /etc/nginx/ssl/enrico-berlinguer/server.crt;     ssl_certificate_key /etc/nginx/ssl/enrico-berlinguer/server.key;     ssl_protocols TLSv1.3;     ssl_ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS;     server_name enrico-berlinguer;     access_log /var/log/nginx/https_access.log;</p> <pre><code>location / {\n    proxy_pass http://red-party;\n    }\n}\n</code></pre> <p>```</p>"},{"location":"practica5/#solucion","title":"Soluci\u00f3n","text":"<p>Habr\u00eda que agregar ssl a la primera l\u00ednea dentro del server, de tal manera que quede </p> <pre><code>server {\n    listen 443 ssl;\n    ssl_certificate /etc/nginx/ssl/enrico-berlinguer/server.crt;\n    ssl_certificate_key /etc/nginx/ssl/enrico-berlinguer/server.key;\n    ssl_protocols TLSv1.3;\n    ssl_ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS;\n    server_name enrico-berlinguer;\n    access_log /var/log/nginx/https_access.log;\n\n    location / {\n        proxy_pass http://red-party;\n        }\n    }\n</code></pre> <p>[!TIP]Cuesti\u00f3n 2</p> <p>Imaginad que intentamos acceder a nuestro sitio web HTTPS y nos encontramos con el siguiente error:</p> <p></p> <p>Investigad qu\u00e9 est\u00e1 pasando y como se ha de solucionar.</p> <p>El error <code>NET::ERR_CERT_REVOKED</code> aparece cuando el certificado SSL de un sitio web ha sido revocado, generalmente debido a problemas de seguridad (como una posible filtraci\u00f3n de claves) o a una revocaci\u00f3n accidental del certificado.</p> <p>Algunas de las maneras para solucionarlo son: * Si eres el administrador del sitio web:    * Verificar la configuraci\u00f3n del servidor.   * Reemplazar el certificado SSL   * Contactar al proveedor del certificado SSL * Si eres un usuario intentando acceder:    * Comrpueba que la fecha y hora de tu dispositivo sea correcta.    * Desactiva el antivirus o firewall.    * Borra el cach\u00e9 DNS del sistema.    * Desactiva el uso de VPN o proxy</p>"},{"location":"practica5/#documentacion","title":"DOCUMENTACI\u00d3N","text":""},{"location":"practica5/#creamos-el-directorio-etcnginxssl","title":"Creamos el directorio /etc/nginx/ssl","text":""},{"location":"practica5/#certificado-con-las-claves-usando-el-comando-sudo-openssl-req-x509-nodes-days-365-newkey-rsa2048-keyout-etcnginxsslserverkey-out-etcnginxsslservercrt","title":"Certificado con las claves usando el comando <code>sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/nginx/ssl/server.key -out /etc/nginx/ssl/server.crt</code>","text":""},{"location":"practica5/#cambiar-el-bloque-server-cambiamos-lo-que-tiene-por","title":"Cambiar el bloque <code>server {...}</code> cambiamos lo que tiene por:","text":"<pre><code>server {\n    listen 443 ssl;\n\n    ssl_certificate /etc/nginx/server.crt;\n    ssl_certificate_key /etc/nginx/ssl/server.key;\n    ssl_protocols TLSv1.3;\n    ssl_ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES128:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS;\n\n    server_name balanceo;\n    access_log /var/log/nginx/https_access.log,\n\n    location / {\n        proxy_pass http://backend_hosts;\n    }\n}\n</code></pre>"},{"location":"practica5/#mensaje-de-error-al-querer-entrar-a-httpsbalanceo","title":"Mensaje de error al querer entrar a <code>https://balanceo</code>","text":""},{"location":"practica5/#mensaje-de-informacion-del-sitio-web","title":"Mensaje de informaci\u00f3n del sitio web","text":""},{"location":"practica5/#pulsamos-en-ver-certificado","title":"Pulsamos en ver certificado","text":""},{"location":"practica5/#escuchamos-puerto-80","title":"Escuchamos puerto 80","text":""},{"location":"practica5/#certificado","title":"Certificado","text":""}]}